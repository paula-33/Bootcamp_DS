{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PeSSukJoQw4-ZmfJWE8QeEssnfGzltT7",
      "authorship_tag": "ABX9TyNt1G06I1xcWODNIXK7JCdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paula-33/Bootcamp_DS/blob/main/03_Multirrotulo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script Completo para Pipeline de Pré-processamento e Modelagem Multirrótulo.\n",
        "\n",
        "A estratégia de modelagem utilizada é a Relevância Binária, implementada com\n",
        "o MultiOutputClassifier do scikit-learn."
      ],
      "metadata": {
        "id": "grkv9dX5KNhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Manipulação e Análise de Dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Pré-processamento e Pipelines\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline # Pipeline compatível com imblearn\n",
        "from skmultilearn.model_selection import IterativeStratification # Para estratificação multi-label\n",
        "\n",
        "\n",
        "# Modelagem\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Métricas de Avaliação\n",
        "from sklearn.metrics import hamming_loss, jaccard_score, classification_report, f1_score\n",
        "\n",
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "dza2pPviumsK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "# --- 1.2. Carregamento dos Dados ---\n",
        "# Carregamos o dataset principal para iniciar a análise.\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Bootcamp DS - Agosto 25/bootcamp_train.csv')\n",
        "\n",
        "# --- 1.3. Análise Confirmatória Rápida ---\n",
        "print(df.shape)\n",
        "print(\"\\n--- Informações Iniciais do Dataset ---\")\n",
        "df.info()\n",
        "print(\"\\n--- 5 Primeiras Linhas do Dataset ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- 5 Últimas Linhas do Dataset ---\")\n",
        "print(df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsN5v6iav7mY",
        "outputId": "5d9190f3-f2ce-4add-d8a8-0945b143c4b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n",
            "(35260, 15)\n",
            "\n",
            "--- Informações Iniciais do Dataset ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35260 entries, 0 to 35259\n",
            "Data columns (total 15 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   id                               35260 non-null  int64  \n",
            " 1   id_produto                       35260 non-null  object \n",
            " 2   tipo                             35260 non-null  object \n",
            " 3   temperatura_ar                   34644 non-null  float64\n",
            " 4   temperatura_processo             34661 non-null  float64\n",
            " 5   umidade_relativa                 35260 non-null  float64\n",
            " 6   velocidade_rotacional            34509 non-null  float64\n",
            " 7   torque                           34637 non-null  float64\n",
            " 8   desgaste_da_ferramenta           34308 non-null  float64\n",
            " 9   falha_maquina                    35260 non-null  object \n",
            " 10  FDF (Falha Desgaste Ferramenta)  35260 non-null  object \n",
            " 11  FDC (Falha Dissipacao Calor)     35260 non-null  object \n",
            " 12  FP (Falha Potencia)              35260 non-null  object \n",
            " 13  FTE (Falha Tensao Excessiva)     35260 non-null  bool   \n",
            " 14  FA (Falha Aleatoria)             35260 non-null  object \n",
            "dtypes: bool(1), float64(6), int64(1), object(7)\n",
            "memory usage: 3.8+ MB\n",
            "\n",
            "--- 5 Primeiras Linhas do Dataset ---\n",
            "   id id_produto tipo  temperatura_ar  temperatura_processo  umidade_relativa  \\\n",
            "0   0     L56434    L           298.3                 309.1              90.0   \n",
            "1   1     L48741    L           298.2                 308.4              90.0   \n",
            "2   2     L48850    L           298.2                 307.8              90.0   \n",
            "3   3     M20947    M           300.9                 310.8              90.0   \n",
            "4   4     L53849    L           -36.0                 310.5              90.0   \n",
            "\n",
            "   velocidade_rotacional  torque  desgaste_da_ferramenta falha_maquina  \\\n",
            "0                 1616.0    31.1                   195.0           não   \n",
            "1                 1388.0    53.8                   137.0           Não   \n",
            "2                 1528.0    31.1                     NaN           Não   \n",
            "3                 1599.0    33.0                     7.0           não   \n",
            "4                 1571.0    33.9                     NaN           não   \n",
            "\n",
            "  FDF (Falha Desgaste Ferramenta) FDC (Falha Dissipacao Calor)  \\\n",
            "0                           False                        False   \n",
            "1                           False                        False   \n",
            "2                               N                        False   \n",
            "3                           False                        False   \n",
            "4                               N                        False   \n",
            "\n",
            "  FP (Falha Potencia)  FTE (Falha Tensao Excessiva) FA (Falha Aleatoria)  \n",
            "0                 Não                         False                  Não  \n",
            "1                 Não                         False                  Não  \n",
            "2                 Não                         False                  Não  \n",
            "3                 Não                         False                  não  \n",
            "4                 não                         False                  Não  \n",
            "\n",
            "--- 5 Últimas Linhas do Dataset ---\n",
            "          id id_produto tipo  temperatura_ar  temperatura_processo  \\\n",
            "35255  35255     L54709    L           300.1                 311.4   \n",
            "35256  35256     L54735    L           300.4                 311.3   \n",
            "35257  35257     L54275    L           300.6                 -38.0   \n",
            "35258  35258     M18165    M           301.3                 310.4   \n",
            "35259  35259     L53432    L           300.8                 310.3   \n",
            "\n",
            "       umidade_relativa  velocidade_rotacional  torque  \\\n",
            "35255              90.0                 1634.0    34.2   \n",
            "35256              90.0                 1597.0    36.2   \n",
            "35257              90.0                 1485.0    35.8   \n",
            "35258              90.0                 1577.0    37.3   \n",
            "35259              90.0                 1438.0    44.1   \n",
            "\n",
            "       desgaste_da_ferramenta falha_maquina FDF (Falha Desgaste Ferramenta)  \\\n",
            "35255                    45.0           não                           False   \n",
            "35256                   112.0             0                           False   \n",
            "35257                    19.0           Não                           False   \n",
            "35258                    43.0           não                           False   \n",
            "35259                   198.0           Não                           False   \n",
            "\n",
            "      FDC (Falha Dissipacao Calor) FP (Falha Potencia)  \\\n",
            "35255                        False                 não   \n",
            "35256                        False                 Não   \n",
            "35257                        False                 Não   \n",
            "35258                        False                 não   \n",
            "35259                        False                 não   \n",
            "\n",
            "       FTE (Falha Tensao Excessiva) FA (Falha Aleatoria)  \n",
            "35255                         False                  Não  \n",
            "35256                         False                  Não  \n",
            "35257                         False                  Não  \n",
            "35258                         False                  não  \n",
            "35259                         False                  Não  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Limpeza e Padronização dos Nomes das Colunas\n",
        "def limpar_nomes_colunas(df):\n",
        "    colunas_limpas = []\n",
        "    for col in df.columns:\n",
        "        col_limpa = col.strip()\n",
        "        col_limpa = re.sub(r'\\s+', '_', col_limpa)\n",
        "        col_limpa = re.sub(r'[\\(\\)]', '', col_limpa)\n",
        "        col_limpa = col_limpa.lower()\n",
        "        colunas_limpas.append(col_limpa)\n",
        "    df.columns = colunas_limpas\n",
        "    return df\n",
        "\n",
        "df = limpar_nomes_colunas(df)\n",
        "print(\"\\nNomes das colunas foram limpos e padronizados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu9STQwByVPp",
        "outputId": "5b87204e-ed1d-425d-8ef8-c45da681edd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nomes das colunas foram limpos e padronizados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "rmxiIP6Gyh5P",
        "outputId": "b34bb1f2-aaf3-41dc-d7d8-deaa020db8bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id id_produto tipo  temperatura_ar  temperatura_processo  umidade_relativa  \\\n",
              "0   0     L56434    L           298.3                 309.1              90.0   \n",
              "1   1     L48741    L           298.2                 308.4              90.0   \n",
              "2   2     L48850    L           298.2                 307.8              90.0   \n",
              "3   3     M20947    M           300.9                 310.8              90.0   \n",
              "\n",
              "   velocidade_rotacional  torque  desgaste_da_ferramenta falha_maquina  \\\n",
              "0                 1616.0    31.1                   195.0           não   \n",
              "1                 1388.0    53.8                   137.0           Não   \n",
              "2                 1528.0    31.1                     NaN           Não   \n",
              "3                 1599.0    33.0                     7.0           não   \n",
              "\n",
              "  fdf_falha_desgaste_ferramenta fdc_falha_dissipacao_calor fp_falha_potencia  \\\n",
              "0                         False                      False               Não   \n",
              "1                         False                      False               Não   \n",
              "2                             N                      False               Não   \n",
              "3                         False                      False               Não   \n",
              "\n",
              "   fte_falha_tensao_excessiva fa_falha_aleatoria  \n",
              "0                       False                Não  \n",
              "1                       False                Não  \n",
              "2                       False                Não  \n",
              "3                       False                não  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1c51fce-dd59-4f28-8025-fd8ebccf591c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>id_produto</th>\n",
              "      <th>tipo</th>\n",
              "      <th>temperatura_ar</th>\n",
              "      <th>temperatura_processo</th>\n",
              "      <th>umidade_relativa</th>\n",
              "      <th>velocidade_rotacional</th>\n",
              "      <th>torque</th>\n",
              "      <th>desgaste_da_ferramenta</th>\n",
              "      <th>falha_maquina</th>\n",
              "      <th>fdf_falha_desgaste_ferramenta</th>\n",
              "      <th>fdc_falha_dissipacao_calor</th>\n",
              "      <th>fp_falha_potencia</th>\n",
              "      <th>fte_falha_tensao_excessiva</th>\n",
              "      <th>fa_falha_aleatoria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>L56434</td>\n",
              "      <td>L</td>\n",
              "      <td>298.3</td>\n",
              "      <td>309.1</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1616.0</td>\n",
              "      <td>31.1</td>\n",
              "      <td>195.0</td>\n",
              "      <td>não</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>L48741</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>308.4</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1388.0</td>\n",
              "      <td>53.8</td>\n",
              "      <td>137.0</td>\n",
              "      <td>Não</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>L48850</td>\n",
              "      <td>L</td>\n",
              "      <td>298.2</td>\n",
              "      <td>307.8</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1528.0</td>\n",
              "      <td>31.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Não</td>\n",
              "      <td>N</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>M20947</td>\n",
              "      <td>M</td>\n",
              "      <td>300.9</td>\n",
              "      <td>310.8</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1599.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>não</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Não</td>\n",
              "      <td>False</td>\n",
              "      <td>não</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1c51fce-dd59-4f28-8025-fd8ebccf591c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1c51fce-dd59-4f28-8025-fd8ebccf591c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1c51fce-dd59-4f28-8025-fd8ebccf591c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c4bf7288-a389-4f70-ab49-293b797fb9e9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4bf7288-a389-4f70-ab49-293b797fb9e9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c4bf7288-a389-4f70-ab49-293b797fb9e9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 35260,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10178,\n        \"min\": 0,\n        \"max\": 35259,\n        \"num_unique_values\": 35260,\n        \"samples\": [\n          32498,\n          31350,\n          31647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_produto\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9708,\n        \"samples\": [\n          \"L51073\",\n          \"M18687\",\n          \"H36945\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"L\",\n          \"M\",\n          \"H\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperatura_ar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96.34222412168937,\n        \"min\": -36.0,\n        \"max\": 304.5,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          302.9,\n          297.9,\n          299.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperatura_processo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96.94362973368727,\n        \"min\": -38.0,\n        \"max\": 313.8,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          311.8,\n          309.1,\n          308.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"umidade_relativa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1421914468933877,\n        \"min\": 80.59042912613194,\n        \"max\": 94.575256258553,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          85.24209951708758,\n          83.00966880899149,\n          88.68525285355072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"velocidade_rotacional\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 494.0987585706413,\n        \"min\": -161.0,\n        \"max\": 2886.0,\n        \"num_unique_values\": 916,\n        \"samples\": [\n          1639.0,\n          1808.0,\n          1446.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"torque\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.831625815186966,\n        \"min\": 3.8,\n        \"max\": 76.6,\n        \"num_unique_values\": 579,\n        \"samples\": [\n          55.0,\n          62.5,\n          68.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"desgaste_da_ferramenta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 110.41193664990492,\n        \"min\": -202.0,\n        \"max\": 253.0,\n        \"num_unique_values\": 247,\n        \"samples\": [\n          17.0,\n          -202.0,\n          182.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"falha_maquina\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"N\\u00e3o\",\n          \"Sim\",\n          \"n\\u00e3o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fdf_falha_desgaste_ferramenta\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"False\",\n          \"N\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fdc_falha_dissipacao_calor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"False\",\n          \"nao\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fp_falha_potencia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"n\\u00e3o\",\n          \"sim\",\n          \"N\\u00e3o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fte_falha_tensao_excessiva\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fa_falha_aleatoria\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"N\\u00e3o\",\n          \"n\\u00e3o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 2. LIMPEZA E PREPARAÇÃO DOS DADOS\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# --- 2.1. Definição das Colunas de Alvo e Features ---\n",
        "# Assuming column names are already standardized by a previous step\n",
        "target_cols = [\n",
        "    'fdf_falha_desgaste_ferramenta',\n",
        "    'fdc_falha_dissipacao_calor',\n",
        "    'fp_falha_potencia',\n",
        "    'fte_falha_tensao_excessiva',\n",
        "    'fa_falha_aleatoria'\n",
        "]\n",
        "\n",
        "id_cols = ['id', 'id_produto']\n",
        "# A coluna 'falha_maquina' é redundante, pois é uma agregação das outras falhas.\n",
        "# Vamos removê-la para focar na predição do *tipo* de falha.\n",
        "redundant_cols = ['falha_maquina']\n",
        "\n",
        "# Features são todas as colunas que não são IDs nem alvos.\n",
        "feature_cols = [col for col in df.columns if col not in target_cols + id_cols + redundant_cols]\n",
        "\n",
        "# Separação inicial para limpeza\n",
        "X = df[feature_cols].copy()\n",
        "y = df[target_cols].copy()\n",
        "\n",
        "# Dicionário de mapeamento para normalizar os valores\n",
        "map_dict = {\n",
        "    'sim': 1, 'Sim': 1, True: 1, 'True': 1, '1': 1, 1:1,\n",
        "    'não': 0, 'nao': 0, 'Não': 0, 'N': 0, False: 0, 'False': 0, '0': 0, 0: 0, '-': 0\n",
        "}\n",
        "# Apply the map_dict to the target columns in y\n",
        "for col in y.columns:\n",
        "    # The .map is efficient for substituting values based on a dictionary.\n",
        "    y[col] = y[col].astype(str).map(map_dict)\n",
        "\n",
        "# Verificar se ainda há valores nulos após o mapeamento\n",
        "print(\"\\n--- Contagem de Nulos nas Colunas Alvo Após Limpeza ---\")\n",
        "print(y.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mkxlzzce4U8",
        "outputId": "fdf36d1c-46bb-4d24-83af-392450ae7bd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contagem de Nulos nas Colunas Alvo Após Limpeza ---\n",
            "fdf_falha_desgaste_ferramenta    0\n",
            "fdc_falha_dissipacao_calor       4\n",
            "fp_falha_potencia                2\n",
            "fte_falha_tensao_excessiva       0\n",
            "fa_falha_aleatoria               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 2.3. Limpeza das Features (X) ---\n",
        "# Justificativa: Erros de digitação ou outliers extremos podem prejudicar o modelo.\n",
        "# A coluna 'temperatura_ar' possui valores como -36.0, que são fisicamente\n",
        "# implausíveis e provavelmente erros de medição. Vamos tratá-los como NaN\n",
        "# para que nosso pipeline de pré-processamento possa imputá-los corretamente.\n",
        "\n",
        "if 'temperatura_ar' in X.columns:\n",
        "    X['temperatura_ar'] = X['temperatura_ar'].apply(lambda temp: np.nan if temp is not None and temp <= 0 else temp)\n",
        "    print(\"\\nValores <= 0 em 'temperatura_ar' tratados como NaN.\")\n",
        "else:\n",
        "    print(\"\\nColuna 'temperatura_ar' não encontrada em X para tratamento de valores.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Dados Limpos e Prontos para Divisão ---\")\n",
        "print(\"Dimensões de X (features):\", X.shape)\n",
        "print(\"Dimensões de y (alvos):\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2duGrtcdw9IO",
        "outputId": "0592516a-a333-4fd8-962b-43f8991782b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valores <= 0 em 'temperatura_ar' tratados como NaN.\n",
            "\n",
            "--- Dados Limpos e Prontos para Divisão ---\n",
            "Dimensões de X (features): (35260, 7)\n",
            "Dimensões de y (alvos): (35260, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2.3. Limpeza das Features (X) ---\n",
        "# Justificativa: Erros de digitação ou outliers extremos podem prejudicar o modelo.\n",
        "# A coluna 'temperatura_ar' possui valores como -36.0, que são fisicamente\n",
        "# implausíveis e provavelmente erros de medição. Vamos tratá-los como NaN\n",
        "# para que nosso pipeline de pré-processamento possa imputá-los corretamente.\n",
        "\n",
        "X['temperatura_ar'] = X['temperatura_ar'].apply(lambda temp: np.nan if temp <= 0 else temp)\n",
        "\n",
        "print(\"\\n--- Dados Limpos e Prontos para Divisão ---\")\n",
        "print(\"Dimensões de X (features):\", X.shape)\n",
        "print(\"Dimensões de y (alvos):\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7fu1QOix3XT",
        "outputId": "8972bbc2-ba18-4532-896a-aa6a6e1ac6df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dados Limpos e Prontos para Divisão ---\n",
            "Dimensões de X (features): (35260, 7)\n",
            "Dimensões de y (alvos): (35260, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. DIVISÃO ESTRATIFICADA DOS DADOS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n--- Criando chave de estratificação manual ---\")\n",
        "\n",
        "# --- Divisão em Treino+Validação (80%) e Teste (20%) ---\n",
        "# A estratificação aqui é MANTIDA.\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Divisão do conjunto Treino+Validação em Treino (75% de 80% = 60% do total)\n",
        "# e Validação (25% de 80% = 20% do total) ---\n",
        "print(\"\\nRealizando a segunda divisão (Treino/Validação) sem estratificação para evitar o erro.\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val,\n",
        "    y_train_val,\n",
        "    test_size=0.25,\n",
        "    random_state=42 # Mantemos o random_state para reprodutibilidade\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- Dimensões dos Conjuntos de Dados (com estratificação parcial) ---\")\n",
        "print(f\"Treino:    X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Validação: X={X_val.shape}, y={y_val.shape}\")\n",
        "print(f\"Teste:     X={X_test.shape}, y={y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL5w4vD92Mjk",
        "outputId": "996c3794-716c-4be8-9876-4bd7c47a6100"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Criando chave de estratificação manual ---\n",
            "\n",
            "Realizando a segunda divisão (Treino/Validação) sem estratificação para evitar o erro.\n",
            "\n",
            "--- Dimensões dos Conjuntos de Dados (com estratificação parcial) ---\n",
            "Treino:    X=(21156, 7), y=(21156, 5)\n",
            "Validação: X=(7052, 7), y=(7052, 5)\n",
            "Teste:     X=(7052, 7), y=(7052, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 4. CONSTRUÇÃO DO PIPELINE DE PRÉ-PROCESSAMENTO\n",
        "# ------------------------------------------------------------------------------\n",
        "# Justificativa: Usar Pipelines é uma das melhores práticas em MLOps.\n",
        "# 1. Evita Data Leakage: O pré-processamento é aprendido apenas nos dados de treino.\n",
        "# 2. Organização: Encapsula todas as etapas de transformação em um único objeto.\n",
        "# 3. Reprodutibilidade: Garante que os mesmos passos sejam aplicados em todos os dados.\n",
        "\n",
        "# Identificação dos tipos de features\n",
        "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "print(f\"\\nFeatures Numéricas: {numeric_features}\")\n",
        "print(f\"Features Categóricas: {categorical_features}\")\n",
        "\n",
        "# --- Pipeline para Features Numéricas ---\n",
        "# 1. SimpleImputer: Preenche valores ausentes (NaN) com a mediana. A mediana é\n",
        "#    mais robusta a outliers do que a média.\n",
        "# 2. StandardScaler: Padroniza as features para terem média 0 e desvio padrão 1.\n",
        "#    Essencial para o desempenho de muitos algoritmos.\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# --- Pipeline para Features Categóricas ---\n",
        "# 1. SimpleImputer: Preenche valores ausentes com o valor mais frequente.\n",
        "# 2. OneHotEncoder: Transforma categorias em colunas binárias. `handle_unknown='ignore'`\n",
        "#    evita erros se uma nova categoria aparecer nos dados de validação ou teste.\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# --- Combinando os Pipelines com ColumnTransformer ---\n",
        "# O ColumnTransformer aplica o pipeline correto a cada tipo de coluna.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Mantém colunas não especificadas (se houver)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krMMA4Q82IT8",
        "outputId": "0ccf9c61-5da6-448e-faeb-6102dd599b2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features Numéricas: ['temperatura_ar', 'temperatura_processo', 'umidade_relativa', 'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']\n",
            "Features Categóricas: ['tipo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor"
      ],
      "metadata": {
        "id": "sI60QHOWgQf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a1a0b97c-7c0a-4416-dd22-03e831ddbb03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(remainder='passthrough',\n",
              "                  transformers=[('num',\n",
              "                                 Pipeline(steps=[('imputer',\n",
              "                                                  SimpleImputer(strategy='median')),\n",
              "                                                 ('scaler', StandardScaler())]),\n",
              "                                 ['temperatura_ar', 'temperatura_processo',\n",
              "                                  'umidade_relativa', 'velocidade_rotacional',\n",
              "                                  'torque', 'desgaste_da_ferramenta']),\n",
              "                                ('cat',\n",
              "                                 Pipeline(steps=[('imputer',\n",
              "                                                  SimpleImputer(strategy='most_frequent')),\n",
              "                                                 ('onehot',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                 ['tipo'])])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                  transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;temperatura_ar&#x27;, &#x27;temperatura_processo&#x27;,\n",
              "                                  &#x27;umidade_relativa&#x27;, &#x27;velocidade_rotacional&#x27;,\n",
              "                                  &#x27;torque&#x27;, &#x27;desgaste_da_ferramenta&#x27;]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;tipo&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
              "                  transformers=[(&#x27;num&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
              "                                 [&#x27;temperatura_ar&#x27;, &#x27;temperatura_processo&#x27;,\n",
              "                                  &#x27;umidade_relativa&#x27;, &#x27;velocidade_rotacional&#x27;,\n",
              "                                  &#x27;torque&#x27;, &#x27;desgaste_da_ferramenta&#x27;]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;tipo&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;temperatura_ar&#x27;, &#x27;temperatura_processo&#x27;, &#x27;umidade_relativa&#x27;, &#x27;velocidade_rotacional&#x27;, &#x27;torque&#x27;, &#x27;desgaste_da_ferramenta&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;tipo&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tratamento de potenciais valores NaN em y_train antes do treinamento ---\n",
        "# Imputar NaNs em y_train com a moda de cada coluna alvo\n",
        "print(\"\\n--- Tratando NaNs em y_train antes de treinar os modelos baseline ---\")\n",
        "y_train_limpo = y_train.copy() # Criar uma cópia para evitar modificar o y_train original\n",
        "\n",
        "for coluna in y_train_limpo.columns:\n",
        "    if y_train_limpo[coluna].isnull().any():\n",
        "        # Calcular a moda dos próprios dados de treinamento\n",
        "        valor_moda_treino = y_train_limpo[coluna].mode()[0] if not y_train_limpo[coluna].mode().empty else 0 # Padrão para 0 se a moda estiver vazia\n",
        "        y_train_limpo[coluna].fillna(valor_moda_treino, inplace=True)\n",
        "        print(f\"  NaNs em y_train['{coluna}'] imputados com a moda ({valor_moda_treino}).\")\n",
        "    else:\n",
        "         print(f\"  Nenhum NaN encontrado em y_train['{coluna}'].\")\n",
        "\n",
        "# Verificar se ainda existem NaNs restantes em y_train_limpo\n",
        "print(\"\\n--- Verificação final de NaNs em y_train_limpo ---\")\n",
        "print(y_train_limpo.isnull().sum())\n",
        "\n",
        "\n",
        "# Verificação final\n",
        "print(\"\\n--- Verificação final após limpeza ---\")\n",
        "total_nans_restantes = y_train_limpo.isnull().sum().sum()\n",
        "if total_nans_restantes == 0:\n",
        "    print(\"✓ Todos os NaNs foram tratados com sucesso!\")\n",
        "else:\n",
        "    print(f\"⚠️ Ainda restam {total_nans_restantes} NaNs nos dados\")\n",
        "\n",
        "print(\"\\nResumo por coluna:\")\n",
        "print(y_train_limpo.isnull().sum())\n",
        "\n",
        "# Mostrar estatísticas básicas após a limpeza\n",
        "print(\"\\n--- Estatísticas básicas após limpeza ---\")\n",
        "print(y_train_limpo.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhhno7jMkDfz",
        "outputId": "375c97d2-9705-48ee-9f49-cf37a92c394c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tratando NaNs em y_train antes de treinar os modelos baseline ---\n",
            "  Nenhum NaN encontrado em y_train['fdf_falha_desgaste_ferramenta'].\n",
            "  NaNs em y_train['fdc_falha_dissipacao_calor'] imputados com a moda (0.0).\n",
            "  Nenhum NaN encontrado em y_train['fp_falha_potencia'].\n",
            "  Nenhum NaN encontrado em y_train['fte_falha_tensao_excessiva'].\n",
            "  Nenhum NaN encontrado em y_train['fa_falha_aleatoria'].\n",
            "\n",
            "--- Verificação final de NaNs em y_train_limpo ---\n",
            "fdf_falha_desgaste_ferramenta    0\n",
            "fdc_falha_dissipacao_calor       0\n",
            "fp_falha_potencia                0\n",
            "fte_falha_tensao_excessiva       0\n",
            "fa_falha_aleatoria               0\n",
            "dtype: int64\n",
            "\n",
            "--- Verificação final após limpeza ---\n",
            "✓ Todos os NaNs foram tratados com sucesso!\n",
            "\n",
            "Resumo por coluna:\n",
            "fdf_falha_desgaste_ferramenta    0\n",
            "fdc_falha_dissipacao_calor       0\n",
            "fp_falha_potencia                0\n",
            "fte_falha_tensao_excessiva       0\n",
            "fa_falha_aleatoria               0\n",
            "dtype: int64\n",
            "\n",
            "--- Estatísticas básicas após limpeza ---\n",
            "       fdf_falha_desgaste_ferramenta  fdc_falha_dissipacao_calor  \\\n",
            "count                   21156.000000                21156.000000   \n",
            "mean                        0.002080                    0.006570   \n",
            "std                         0.045558                    0.080792   \n",
            "min                         0.000000                    0.000000   \n",
            "25%                         0.000000                    0.000000   \n",
            "50%                         0.000000                    0.000000   \n",
            "75%                         0.000000                    0.000000   \n",
            "max                         1.000000                    1.000000   \n",
            "\n",
            "       fp_falha_potencia  fte_falha_tensao_excessiva  fa_falha_aleatoria  \n",
            "count       21156.000000                21156.000000        21156.000000  \n",
            "mean            0.003734                    0.004774            0.001985  \n",
            "std             0.060995                    0.068931            0.044513  \n",
            "min             0.000000                    0.000000            0.000000  \n",
            "25%             0.000000                    0.000000            0.000000  \n",
            "50%             0.000000                    0.000000            0.000000  \n",
            "75%             0.000000                    0.000000            0.000000  \n",
            "max             1.000000                    1.000000            1.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3076938203.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  y_train_limpo[coluna].fillna(valor_moda_treino, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. MODELAGEM E TREINAMENTO (BASELINE)\n",
        "# ------------------------------------------------------------------------------\n",
        "# Justificativa: Antes de otimizar, criamos uma baseline com modelos robustos\n",
        "# e suas configurações padrão. Isso nos dá um ponto de partida para entender\n",
        "# a complexidade do problema e comparar melhorias futuras.\n",
        "\n",
        "\n",
        "# --- 5.1. Definição dos Modelos ---\n",
        "# Usamos o wrapper `MultiOutputClassifier` para que modelos que não suportam\n",
        "# nativamente múltiplas saídas (como XGBoost e LightGBM) possam ser usados.\n",
        "# Ele treina um classificador separado para cada coluna de alvo.\n",
        "\n",
        "# Dicionário de modelos para facilitar a iteração\n",
        "models = {\n",
        "    \"Random Forest\": MultiOutputClassifier(RandomForestClassifier(random_state=42, class_weight='balanced')),\n",
        "    \"XGBoost\": MultiOutputClassifier(xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
        "    \"LightGBM\": MultiOutputClassifier(lgb.LGBMClassifier(random_state=42, class_weight='balanced'))\n",
        "}\n",
        "\n",
        "# --- 5.2. Criação dos Pipelines Finais (Pré-processador + Modelo) ---\n",
        "# Justificativa para Balanceamento: O dataset é desbalanceado. Em vez de SMOTE,\n",
        "# que é complexo para multi-label, usamos o argumento `class_weight='balanced'`\n",
        "# nos modelos que o suportam (Random Forest, LightGBM). Isso ajusta os pesos\n",
        "# das amostras de forma inversamente proporcional à frequência das classes,\n",
        "# penalizando mais os erros nas classes minoritárias. Para o XGBoost, isso pode\n",
        "# ser ajustado com `scale_pos_weight`, mas faremos isso na etapa de otimização.\n",
        "\n",
        "pipelines = {}\n",
        "for name, model in models.items():\n",
        "    pipelines[name] = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "# --- 5.3. Treinamento e Avaliação da Baseline ---\n",
        "results = {}\n",
        "for name, pipeline in pipelines.items():\n",
        "    print(f\"\\n--- Treinando o modelo: {name} ---\")\n",
        "\n",
        "    # Treinamento com os dados de treino LIMPOS (y_train_limpo)\n",
        "    pipeline.fit(X_train, y_train_limpo)\n",
        "\n",
        "    # Previsões nos dados de validação\n",
        "    # Ensure y_val is also cleaned of NaNs before evaluation\n",
        "    y_val_cleaned_for_eval = y_val.copy()\n",
        "    for col in y_val_cleaned_for_eval.columns:\n",
        "        if y_val_cleaned_for_eval[col].isnull().any():\n",
        "             # Use mode from the training data for consistency and to prevent leakage\n",
        "             mode_value_train = y_train_limpo[col].mode()[0] if not y_train_limpo[col].mode().empty else 0\n",
        "             y_val_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
        "\n",
        "\n",
        "    y_pred = pipeline.predict(X_val)\n",
        "\n",
        "    # Cálculo das métricas\n",
        "    # Hamming Loss: Fração de rótulos previstos incorretamente. Menor é melhor.\n",
        "    # Jaccard Score: Similaridade entre o conjunto de rótulos verdadeiros e previstos. Maior é melhor.\n",
        "    # F1-Score (Weighted): Média ponderada do F1-score, considerando o suporte de cada classe.\n",
        "    h_loss = hamming_loss(y_val_cleaned_for_eval, y_pred)\n",
        "    j_score = jaccard_score(y_val_cleaned_for_eval, y_pred, average='samples')\n",
        "    f1_w = f1_score(y_val_cleaned_for_eval, y_pred, average='weighted')\n",
        "\n",
        "    results[name] = {\n",
        "        'Hamming Loss': h_loss,\n",
        "        'Jaccard Score': j_score,\n",
        "        'Weighted F1-Score': f1_w,\n",
        "        'Classification Report': classification_report(y_val_cleaned_for_eval, y_pred, target_names=target_cols, zero_division=0)\n",
        "    }\n",
        "\n",
        "    print(f\"Resultados de {name} no conjunto de validação:\")\n",
        "    print(f\"  Hamming Loss: {h_loss:.4f}\")\n",
        "    print(f\"  Jaccard Score (samples): {j_score:.4f}\")\n",
        "    print(f\"  Weighted F1-Score: {f1_w:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pHUgnvH4Txg",
        "outputId": "89c6c354-c92c-4416-cb06-9651f0637027"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Treinando o modelo: Random Forest ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-892873067.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  y_val_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [20:37:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de Random Forest no conjunto de validação:\n",
            "  Hamming Loss: 0.0033\n",
            "  Jaccard Score (samples): 0.0028\n",
            "  Weighted F1-Score: 0.2427\n",
            "\n",
            "--- Treinando o modelo: XGBoost ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [20:37:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/tmp/ipython-input-892873067.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  y_val_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de XGBoost no conjunto de validação:\n",
            "  Hamming Loss: 0.0033\n",
            "  Jaccard Score (samples): 0.0055\n",
            "  Weighted F1-Score: 0.3743\n",
            "\n",
            "--- Treinando o modelo: LightGBM ---\n",
            "[LightGBM] [Info] Number of positive: 44, number of negative: 21112\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 21017\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 79, number of negative: 21077\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 101, number of negative: 21055\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 42, number of negative: 21114\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-892873067.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  y_val_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de LightGBM no conjunto de validação:\n",
            "  Hamming Loss: 0.0044\n",
            "  Jaccard Score (samples): 0.0091\n",
            "  Weighted F1-Score: 0.4606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. ANÁLISE COMPARATIVA E ESCOLHA DO MODELO\n",
        "# ------------------------------------------------------------------------------\n",
        "# Justificativa: Consolidamos os resultados para tomar uma decisão informada\n",
        "# sobre qual modelo seguir para a otimização e avaliação final.\n",
        "\n",
        "# --- 6.1. Tabela Comparativa ---\n",
        "results_df = pd.DataFrame(results).T[['Hamming Loss', 'Jaccard Score', 'Weighted F1-Score']]\n",
        "results_df = results_df.sort_values(by='Weighted F1-Score', ascending=False)\n",
        "print(\"\\n\\n--- Tabela Comparativa de Desempenho dos Modelos (Baseline) ---\")\n",
        "print(results_df)\n",
        "\n",
        "# --- 6.2. Visualização Comparativa ---\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "results_df['Hamming Loss'].sort_values().plot(kind='barh', ax=ax[0], color='skyblue')\n",
        "ax[0].set_title('Hamming Loss (Menor é Melhor)')\n",
        "ax[0].set_xlabel('Perda')\n",
        "\n",
        "results_df['Weighted F1-Score'].sort_values().plot(kind='barh', ax=ax[1], color='salmon')\n",
        "ax[1].set_title('Weighted F1-Score (Maior é Melhor)')\n",
        "ax[1].set_xlabel('Pontuação F1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "9qMIql-w4t6o",
        "outputId": "3f11c847-e866-4a0c-a2be-0f9988a943f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Tabela Comparativa de Desempenho dos Modelos (Baseline) ---\n",
            "              Hamming Loss Jaccard Score Weighted F1-Score\n",
            "LightGBM          0.004424      0.009146          0.460584\n",
            "XGBoost           0.003318       0.00553          0.374331\n",
            "Random Forest     0.003318      0.002836          0.242652\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 6.3. Relatórios Detalhados por Classe ---\n",
        "for name, result in results.items():\n",
        "    print(f\"\\n--- Relatório de Classificação Detalhado para: {name} ---\")\n",
        "    print(result['Classification Report'])\n",
        "\n",
        "# --- 6.4. Conclusão da Baseline e Escolha do Modelo ---\n",
        "# Seleciona o melhor modelo com base no Weighted F1-Score\n",
        "best_model_name = results_df.index[0]\n",
        "best_pipeline = pipelines[best_model_name]\n",
        "\n",
        "print(f\"\\n\\n--- Conclusão da Baseline ---\")\n",
        "print(f\"O modelo com melhor desempenho inicial foi o '{best_model_name}' com um F1-Score ponderado de {results_df.loc[best_model_name, 'Weighted F1-Score']:.4f}.\")\n",
        "print(\"Este modelo será levado para a avaliação final no conjunto de teste.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnyUjwM40xy",
        "outputId": "c8c5c21c-4e76-4a46-9785-a20002e71609"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Relatório de Classificação Detalhado para: Random Forest ---\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "fdf_falha_desgaste_ferramenta       0.00      0.00      0.00        14\n",
            "   fdc_falha_dissipacao_calor       0.82      0.23      0.36        39\n",
            "            fp_falha_potencia       0.73      0.30      0.42        27\n",
            "   fte_falha_tensao_excessiva       0.43      0.09      0.15        32\n",
            "           fa_falha_aleatoria       0.00      0.00      0.00        13\n",
            "\n",
            "                    micro avg       0.62      0.16      0.25       125\n",
            "                    macro avg       0.39      0.12      0.19       125\n",
            "                 weighted avg       0.52      0.16      0.24       125\n",
            "                  samples avg       0.00      0.00      0.00       125\n",
            "\n",
            "\n",
            "--- Relatório de Classificação Detalhado para: XGBoost ---\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "fdf_falha_desgaste_ferramenta       0.20      0.07      0.11        14\n",
            "   fdc_falha_dissipacao_calor       0.62      0.51      0.56        39\n",
            "            fp_falha_potencia       0.69      0.41      0.51        27\n",
            "   fte_falha_tensao_excessiva       0.47      0.22      0.30        32\n",
            "           fa_falha_aleatoria       0.00      0.00      0.00        13\n",
            "\n",
            "                    micro avg       0.56      0.31      0.40       125\n",
            "                    macro avg       0.40      0.24      0.30       125\n",
            "                 weighted avg       0.49      0.31      0.37       125\n",
            "                  samples avg       0.01      0.01      0.01       125\n",
            "\n",
            "\n",
            "--- Relatório de Classificação Detalhado para: LightGBM ---\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "fdf_falha_desgaste_ferramenta       0.14      0.21      0.17        14\n",
            "   fdc_falha_dissipacao_calor       0.54      0.87      0.67        39\n",
            "            fp_falha_potencia       0.65      0.56      0.60        27\n",
            "   fte_falha_tensao_excessiva       0.36      0.47      0.41        32\n",
            "           fa_falha_aleatoria       0.00      0.00      0.00        13\n",
            "\n",
            "                    micro avg       0.41      0.54      0.46       125\n",
            "                    macro avg       0.34      0.42      0.37       125\n",
            "                 weighted avg       0.42      0.54      0.46       125\n",
            "                  samples avg       0.01      0.01      0.01       125\n",
            "\n",
            "\n",
            "\n",
            "--- Conclusão da Baseline ---\n",
            "O modelo com melhor desempenho inicial foi o 'LightGBM' com um F1-Score ponderado de 0.4606.\n",
            "Este modelo será levado para a avaliação final no conjunto de teste.\n",
            "NOTA: Uma etapa de otimização de hiperparâmetros (com GridSearchCV ou RandomizedSearchCV) seria o próximo passo ideal em um projeto real.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise conclusiva\n",
        "\n",
        "**LightGBM: Melhor Modelo Geral**\n",
        "O LightGBM confirma sua superioridade com Weighted F1-Score de 0.46 e melhor capacidade de detecção balanceada (micro recall 0.54), demonstrando eficácia particular em falhas térmicas (F1=0.67) e falhas de potência (F1=0.60). É o único modelo que consegue alguma detecção de desgaste de ferramenta (F1=0.17), embora ainda limitada.\n",
        "\n",
        "**Performance por Tipo de Falha**\n",
        "\n",
        "- Falhas Bem Detectadas:\n",
        "\n",
        "Dissipação de calor: LightGBM lidera (F1=0.67, recall=0.87)\n",
        "Falha de potência: Performance consistente entre XGBoost (F1=0.51) e LightGBM (F1=0.60).\n",
        "\n",
        "- Falhas Parcialmente Detectadas:\n",
        "\n",
        "Tensão excessiva: LightGBM mostra melhor recall (0.47) vs XGBoost (0.22)\n",
        "Desgaste de ferramenta: Apenas LightGBM detecta (recall=0.21)\n",
        "\n",
        "- Falha Crítica Não Detectada:\n",
        "\n",
        "- Falhas aleatórias: Zero detecção em todos os modelos (13 amostras insuficientes)\n",
        "\n",
        "**Trade-offs Operacionais**\n",
        "\n",
        "- Random Forest: Alta precisão (0.82 para dissipação) mas recall baixíssimo (0.16 micro avg) - inadequado para manutenção crítica\n",
        "\n",
        "- XGBoost: Equilibrio médio com boa precisão (0.49 weighted avg)\n",
        "- LightGBM: Melhor recall geral (0.54) essencial para não perder falhas críticas.\n",
        "\n",
        "**Recomendação Estratégica**\n",
        "\n",
        "Para manutenção preditiva industrial, o LightGBM é a escolha ideal por maximizar a detecção de falhas térmicas (87% recall) e falhas de potência (56% recall), que representam os modos críticos mais frequentes. Necessário implementar sistema híbrido com monitoramento especializado para falhas aleatórias e coleta adicional de dados para desgaste de ferramenta."
      ],
      "metadata": {
        "id": "7b8zlNgZ-ieo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 8. ANÁLISE DE FEATURES IMPORTANTES\n",
        "# ------------------------------------------------------------------------------\n",
        "# Justificativa: Entender *por que* o modelo toma certas decisões é tão\n",
        "# importante quanto sua precisão. A análise de importância de features nos\n",
        "# dá insights valiosos sobre quais variáveis mais influenciam a previsão de falhas.\n",
        "\n",
        "# Acessando o estimador final dentro do pipeline e do MultiOutputClassifier\n",
        "# Isso pode ser um pouco complexo devido às camadas de abstração.\n",
        "# Verificamos se o modelo é baseado em árvore (tem 'feature_importances_').\n",
        "try:\n",
        "    # Acessa o passo 'classifier' do pipeline\n",
        "    classifier_step = best_pipeline.named_steps['classifier']\n",
        "\n",
        "    # Acessa os estimadores individuais dentro do MultiOutputClassifier\n",
        "    feature_importances = [\n",
        "        estimator.feature_importances_ for estimator in classifier_step.estimators_\n",
        "    ]\n",
        "\n",
        "    # Calcula a importância média entre todos os classificadores de saída\n",
        "    avg_importances = np.mean(feature_importances, axis=0)\n",
        "\n",
        "    # Recupera os nomes das features após o pré-processamento\n",
        "    # Isso é um pouco mais avançado, pois envolve obter os nomes das colunas\n",
        "    # geradas pelo OneHotEncoder\n",
        "    feature_names_raw = best_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "    # Cria um DataFrame para visualização\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names_raw,\n",
        "        'Importance': avg_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(\"\\n\\n--- Importância das Features (Média entre todas as falhas) ---\")\n",
        "    print(importance_df.head(10))\n",
        "\n",
        "    # Visualização\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
        "    plt.title(f'Top 10 Features Mais Importantes - Modelo {best_model_name}')\n",
        "    plt.xlabel('Importância')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except AttributeError:\n",
        "    print(f\"\\nO modelo {best_model_name} não suporta a análise de 'feature_importances_'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3c07ppw5ueWW",
        "outputId": "5bef14c0-8f8b-45a1-d15f-cc0ab0abbb7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Importância das Features (Média entre todas as falhas) ---\n",
            "                       Feature  Importance\n",
            "4                  num__torque       675.4\n",
            "5  num__desgaste_da_ferramenta       658.4\n",
            "3   num__velocidade_rotacional       608.2\n",
            "0          num__temperatura_ar       509.8\n",
            "1    num__temperatura_processo       450.4\n",
            "7                  cat__tipo_L        48.2\n",
            "8                  cat__tipo_M        33.4\n",
            "6                  cat__tipo_H        16.2\n",
            "2        num__umidade_relativa         0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3981611391.py:39: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKYAAAMWCAYAAADLc44dAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAm55JREFUeJzs3Xt8z/X///H7m9l5Y5jDHDZsmDNDQplDhnJmRYmSKGfmlNOGci5KVPowyqEcU3JKJkYoh8hyWGbSCmFsMmyv3x9+e3+9bWOb5eVwu14u78un9/P1ej1fj9dr7/f67N7z+XxZDMMwBAAAAAAAANxnucwuAAAAAAAAAI8ngikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAABkW2hoqCwWi9llAGn4+PioW7du2TrWYrEoNDQ0R+u5m8DAQAUGBmb72EqVKuVsQQBwnxBMAQDwkLJYLJl6RURE/Oe1zJkzRx07dlTJkiVlsVju+MfgxYsX9frrr8vT01MuLi5q2LCh9u7dm6nzBAYGZnidv/32Ww5dja3Zs2crPDz8P+n7fki9P6+99lq620eOHGnd59y5c/e5Ols+Pj567rnnTK3hXhw+fFihoaGKiYn5z8/1559/KjQ0VPv37//Pz3UvIiIirJ+vzz//PN196tWrJ4vF8kgHKxaLRX369DG7jEx9brZt26bg4GAVK1ZM9vb2yps3r5544gmNGzdOf//9t82+t/9Otre3V6lSpfT666/r1KlTNvuGh4db99u+fXua8xqGoRIlSshisTzUvwcAZJ2d2QUAAIDs+eyzz2zeL1y4UJs2bUrT7u/v/5/XMnnyZF2+fFm1a9dWXFxchvulpKTo2Wef1YEDBzRkyBAVLFhQs2fPVmBgoH7++Wf5+fnd9VzFixfXxIkT07R7eXnd0zVkZPbs2SpYsGC2R148CBwdHbVixQrNnj1b9vb2NtuWLFkiR0dHXb16NVt9jxo1SsOHD8+JMh96hw8fVlhYmAIDA+Xj4/OfnuvPP/9UWFiYfHx8VK1atf/0XDnB0dFRixcv1ksvvWTTHhMTox07dsjR0dGkyh4cGzdu/M/PcbfPzZgxYzR+/HiVLl1a3bp1U+nSpXX16lX9/PPPmj59uhYsWKDo6GibY279nXzt2jUdPnxYH330kTZs2KCoqCg5Ozvb7J/6Wahfv75N+9atW/XHH3/IwcEhZy8awAOPYAoAgIfU7X/g/fjjj9q0aVOa9vth69at1tFSrq6uGe63fPly7dixQ8uWLVOHDh0kScHBwSpbtqzGjh2rxYsX3/VcefPmNeUac5JhGLp69aqcnJzuy/maNWumNWvWaN26dWrdurW1fceOHTpx4oTat2+vFStWZKtvOzs72dk93v+X8urVq2kCP9hq0aKF1qxZo3PnzqlgwYLW9sWLF6tw4cLy8/PThQsXTKzQfGZ/hr744guNHz9ewcHB+uyzz9LU89577+m9995Lc1x6v5NLlSqlPn36KDIyUs8884zNthYtWmjZsmV6//33bX53LF68WAEBAaaP3ARw/zGVDwCAR1hiYqIGDx6sEiVKyMHBQeXKldO0adNkGIbNfqnTTBYtWqRy5crJ0dFRAQEB+uGHHzJ1Hm9v70ytM7R8+XIVLlxY7dq1s7Z5enoqODhYX331lZKSkrJ2gelISkrS2LFj5evrKwcHB5UoUUJDhw5N0/f8+fPVqFEjFSpUSA4ODqpQoYLmzJljs4+Pj49+/fVXbd261ToFJXUNmIzWVkqdrnLrdK7UKWobNmxQzZo15eTkpI8//ljSzamNAwYMsP6MfH19NXnyZKWkpNj0u3TpUgUEBMjNzU3u7u6qXLmyZs6cmal7UqxYMT399NNpgr9FixapcuXK6U6h2rZtm3V6Zup9HDhwoP7991+b/dK7D5s2bVL9+vWVL18+ubq6qly5cnrrrbcyVeutYmJiZLFYNG3aNH344YcqXbq0nJ2d1bRpU506dUqGYWj8+PEqXry4nJyc1Lp1a50/f96mj9R7v3HjRlWrVk2Ojo6qUKGCVq5cmeZ8v//+uzp27Kj8+fPL2dlZderU0dq1a232SZ2atnTpUo0aNUrFihWTs7Oz3n//fXXs2FGS1LBhwzRTab/66is9++yz8vLykoODg8qUKaPx48crOTnZpv/UtYIOHz6shg0bytnZWcWKFdOUKVNsaqhVq5Yk6ZVXXrGe69Ypp7t27VKzZs2UN29eOTs7q0GDBoqMjLQ51+XLlzVgwAD5+PjIwcFBhQoV0jPPPJPpqbVZ0bp1azk4OGjZsmU27YsXL1ZwcLBy586d5pgbN25o/PjxKlOmjBwcHOTj46O33norzXfZMAxNmDBBxYsXl7Ozsxo2bKhff/013Toy+31Lz759+9S8eXO5u7vL1dVVjRs31o8//piFu3Bn6a0xdfLkSbVq1UouLi4qVKiQBg4cqA0bNmQ4TftePjdjxoxRwYIF9b///S/dkCxv3ryZXnerSJEikpRuaN2pUyf9888/2rRpk7Xt2rVrWr58uTp37pyp/gE8Wh7v/7wFAMAjzDAMtWrVSlu2bFH37t1VrVo1bdiwQUOGDNHp06fT/JfvrVu36osvvlC/fv3k4OCg2bNnq1mzZtq9e3eOrf2yb98+1ahRQ7ly2f63sdq1a+uTTz7R0aNHVbly5Tv2kZycnOa/qDs6OsrV1VUpKSlq1aqVtm/frtdff13+/v46ePCg3nvvPR09elSrV6+2HjNnzhxVrFhRrVq1kp2dnb7++mu9+eabSklJUe/evSVJM2bMUN++feXq6qqRI0dKkgoXLpytaz9y5Ig6deqknj17qkePHipXrpyuXLmiBg0a6PTp0+rZs6dKliypHTt2aMSIEYqLi9OMGTMk3Qx6OnXqpMaNG2vy5MmSpKioKEVGRqp///6ZOn/nzp3Vv39/JSQkyNXVVTdu3NCyZcs0aNCgdKfxLVu2TFeuXNEbb7yhAgUKaPfu3frggw/0xx9/pAkXbvXrr7/queeeU5UqVTRu3Dg5ODjo+PHjaUKRrFi0aJGuXbumvn376vz585oyZYqCg4PVqFEjRUREaNiwYTp+/Lg++OADhYSEaN68eTbHHzt2TM8//7x69eqlrl27av78+erYsaPWr19vHc3x999/q27durpy5Yr69eunAgUKaMGCBWrVqpWWL1+utm3b2vQ5fvx42dvbKyQkRElJSWratKn69eun999/X2+99ZZ1Cm3q/4aHh8vV1VWDBg2Sq6urvv/+e40ZM0aXLl3S1KlTbfq+cOGCmjVrpnbt2ik4OFjLly/XsGHDVLlyZTVv3lz+/v4aN26cxowZo9dff11PPfWUJKlu3bqSpO+//17NmzdXQECAxo4dq1y5clmD2G3btql27dqSpF69emn58uXq06ePKlSooH/++Ufbt29XVFSUatSoke2fV3qcnZ3VunVrLVmyRG+88YYk6cCBA/r111/16aef6pdffklzzGuvvaYFCxaoQ4cOGjx4sHbt2qWJEycqKipKq1atsu43ZswYTZgwQS1atFCLFi20d+9eNW3aVNeuXbPpL7Pft/T8+uuveuqpp+Tu7q6hQ4cqT548+vjjjxUYGKitW7fqiSeeyJkbdYvExEQ1atRIcXFx6t+/v4oUKaLFixdry5Yt6e5/L5+bo0eP6ujRo3rttdfuOOo1Pbf+Tr5+/bqioqKs/3GgXr16afb38fHRk08+qSVLlqh58+aSpHXr1ik+Pl4vvPCC3n///SydH8AjwAAAAI+E3r17G7f+q3316tWGJGPChAk2+3Xo0MGwWCzG8ePHrW2SDEnGTz/9ZG07efKk4ejoaLRt2zZLdbi4uBhdu3bNcNurr76apn3t2rWGJGP9+vV37LtBgwbWWm99pZ7vs88+M3LlymVs27bN5riPPvrIkGRERkZa265cuZKm/6CgIKN06dI2bRUrVjQaNGiQZt+xY8ca6f1fqfnz5xuSjBMnTljbvL29072+8ePHGy4uLsbRo0dt2ocPH27kzp3biI2NNQzDMPr372+4u7sbN27cSHtT7kKS0bt3b+P8+fOGvb298dlnnxmGcfOeWywWIyYmxnotZ8+etR6X3v2ZOHGiYbFYjJMnT2Z4H9577700fWWWt7e38eyzz1rfnzhxwpBkeHp6GhcvXrS2jxgxwpBkVK1a1bh+/bq1vVOnToa9vb1x9epVmz4lGStWrLC2xcfHG0WLFjWqV69ubRswYIAhyeazc/nyZaNUqVKGj4+PkZycbBiGYWzZssWQZJQuXTrNPVq2bJkhydiyZUuaa0vvfvbs2dNwdna2qTf1M75w4UJrW1JSklGkSBGjffv21rY9e/YYkoz58+fb9JmSkmL4+fkZQUFBRkpKis35S5UqZTzzzDPWtrx58xq9e/dOU1dOSr1fy5YtM7755hvDYrFYP9dDhgyxft8aNGhgVKxY0Xrc/v37DUnGa6+9ZtNfSEiIIcn4/vvvDcMwjDNnzhj29vbGs88+a3O9b731ls3vBsPI/PfNMG5+b8aOHWt936ZNG8Pe3t6Ijo62tv3555+Gm5ub8fTTT9/1PqR+D++kQYMGNr9rpk+fbkgyVq9ebW37999/jfLly6f5nN3r5+arr74yJBkzZsywaU9JSTHOnj1r87r1O5fR72R/f3/j999/t+kr9Xfjnj17jFmzZhlubm7W70XHjh2Nhg0bGoaR9vcAgEcfU/kAAHhEffvtt8qdO7f69etn0z548GAZhqF169bZtD/55JMKCAiwvi9ZsqRat26tDRs2pJlulF3//vtvugvbpi58fPs0sfT4+Pho06ZNNq+hQ4dKujnKx9/fX+XLl9e5c+esr0aNGkmSzUiDW9d3io+P17lz59SgQQP9/vvvio+Pv6frTE+pUqUUFBRk07Zs2TI99dRT8vDwsKm3SZMmSk5Otk6lzJcvnxITE22mvmSVh4eHmjVrpiVLlki6OYWqbt268vb2Tnf/W+9PYmKizp07p7p168owDO3bty/D8+TLl0/SzalrmZkelRkdO3ZU3rx5re9TR6e89NJLNlOFnnjiCV27dk2nT5+2Od7Ly8tmxJO7u7tefvll7du3T3/99Zekm9+X2rVr2yzI7Orqqtdff10xMTE6fPiwTZ9du3bN0hpht+57+fJlnTt3Tk899ZSuXLmS5omSrq6uNmv22Nvbq3bt2vr999/vep79+/fr2LFj6ty5s/755x/rZyoxMVGNGzfWDz/8YP255MuXT7t27dKff/6Z6eu4F02bNlX+/Pm1dOlSGYahpUuXqlOnTunu++2330qSBg0aZNM+ePBgSbJOsfzuu++so+lunVI6YMCANH1m9vt2u+TkZG3cuFFt2rRR6dKlre1FixZV586dtX37dl26dCnzNyKT1q9fr2LFiqlVq1bWNkdHR/Xo0SPd/e/lc5Na/+2jpeLj4+Xp6Wnzuv2Jfrf+Tl63bp1mzJih+Ph4NW/eXGfPnk33fMHBwfr333/1zTff6PLly/rmm2+Yxgc8xpjKBwDAI+rkyZPy8vKSm5ubTXvq1KKTJ0/atKf3RLyyZcvqypUrOnv2rHXNkHvh5OSU7jpSqVPJMvOHvouLi5o0aZLutmPHjikqKkqenp7pbj9z5oz1nyMjIzV27Fjt3LlTV65csdkvPj7eJgjJCaVKlUq33l9++eWu9b755pv68ssv1bx5cxUrVkxNmzZVcHCwmjVrlqUaOnfurC5duig2NlarV6+2WX/mdrGxsRozZozWrFmTZlHqOwV3zz//vD799FO99tprGj58uBo3bqx27dqpQ4cOaaZwZlbJkiVt3qf+bEqUKJFu++31+vr6plkHq2zZspJurmNVpEgRnTx5Mt3pWLd+X26d0prez/NOfv31V40aNUrff/99mhDj9vtZvHjxNPV6eHikO93tdseOHZN0MzjLSHx8vDw8PDRlyhR17dpVJUqUUEBAgFq0aKGXX37ZJny53bVr19Ks4+Xp6ZnuGlG3y5Mnjzp27KjFixerdu3aOnXqVIZhxMmTJ5UrVy75+vratBcpUkT58uWz/v5K/d/bf395enrKw8PDpi2z37fbnT17VleuXFG5cuXSbPP391dKSopOnTqlihUrpnt8dp08eVJlypRJ81m4/Z6kupfPTeq/JxISEmzaXV1drYH4xo0b00w7ldL+Tm7WrJnq16+vmjVratKkSZo+fXqaYzw9PdWkSRMtXrxYV65cUXJysvWBGAAePwRTAADgvilatKji4uLStKe2eXl53VP/KSkpqly5st599910t6cGGdHR0WrcuLHKly+vd999VyVKlJC9vb2+/fZbvffee5ka6ZPRYu8ZjS5LL3RLSUnRM888Yx3xdbvU8KRQoULav3+/NmzYoHXr1mndunWaP3++Xn75ZS1YsOCutaZq1aqVHBwc1LVrVyUlJSk4ODjDa3jmmWd0/vx5DRs2TOXLl5eLi4tOnz6tbt263fH+ODk56YcfftCWLVu0du1arV+/Xl988YUaNWqkjRs3ZirAuF1Gx2TUbty2uP9/ISujpS5evKgGDRrI3d1d48aNU5kyZeTo6Ki9e/dq2LBhae7nvVxXal9Tp05VtWrV0t0ndVRMcHCwnnrqKa1atcoaOkyePFkrV660rv1zux07dqhhw4Y2bSdOnJCPj89da5NuhqMfffSRQkNDVbVqVVWoUOGO+2fmoQqZldnv28PqXj435cuXlyQdOnTIpt3Ozs4aOv3xxx+ZriUgIEB58+a94wM0OnfurB49euivv/5S8+bNraMtATx+CKYAAHhEeXt767vvvtPly5dtRk2lThu6fQpX6kiLWx09elTOzs4ZjjDIqmrVqmnbtm1KSUmxGT2za9cuOTs73/MfhmXKlNGBAwfUuHHjO/5B+/XXXyspKUlr1qyxGY2T3qLCGfWTOhrj4sWLNn9Q3T4S7W71JiQkZDgC7Fb29vZq2bKlWrZsqZSUFL355pv6+OOPNXr06AxHUNzOyclJbdq00eeff67mzZurYMGC6e538OBBHT16VAsWLNDLL79sbc/sVMJcuXKpcePGaty4sd5991298847GjlypLZs2ZKpa81px48fl2EYNj/Lo0ePSpI1UPH29taRI0fSHJvR9yU9GX1WIiIi9M8//2jlypV6+umnre0nTpzI9DVk9lxlypSRdHO6YmbuddGiRfXmm2/qzTff1JkzZ1SjRg29/fbbGQZTVatWTfM5yMpoyvr166tkyZKKiIiwLuSfHm9vb6WkpOjYsWPWUWvSzUXqL168aP15pP7vsWPHbEZ6nT17Ns3Iuax8327l6ekpZ2fnDD8fuXLlSjN6Lyd4e3vr8OHDaT67x48fz3afGX1uypUrJz8/P61evVozZsyQi4tLts+RKjk5Oc0IrFu1bdtWPXv21I8//qgvvvjins8H4OHFGlMAADyiWrRooeTkZM2aNcum/b333pPFYknzh+fOnTttHhN/6tQpffXVV2ratGm2Rrmkp0OHDvr777+1cuVKa9u5c+e0bNkytWzZMt31p7IiODhYp0+f1ty5c9Ns+/fff5WYmCjp/0YW3DqSID4+XvPnz09znIuLiy5evJimPTUAuHVEQGJiYpZGMAUHB2vnzp3asGFDmm0XL17UjRs3JEn//POPzbZcuXKpSpUqkpTu1Mg7CQkJ0dixYzV69OgM90nv/hiGoZkzZ961/9uneUmyjtzJaq055c8//7R5itulS5e0cOFCVatWzRqqtGjRQrt379bOnTut+yUmJuqTTz6Rj4/PXUf2SLL+MX/75yW9+3nt2jXNnj0729eU0bkCAgJUpkwZTZs2Ld1QIHXNn+Tk5DRTCAsVKiQvL687/pw8PDzUpEkTm1fqGnGZYbFY9P7772vs2LHq0qVLhvu1aNFCktI8KS91NOSzzz4rSWrSpIny5MmjDz74wOb+pveEvcx+326XO3duNW3aVF999ZViYmKs7X///bcWL16s+vXry93dPcNrya6goCCdPn1aa9assbZdvXo13d9vmZXR50aSQkNDde7cOfXo0UPXr19Psz0rIxG3bNmihIQEVa1aNcN9XF1dNWfOHIWGhqply5aZ7hvAo4cRUwAAPKJatmyphg0bauTIkYqJiVHVqlW1ceNGffXVVxowYIA1WElVqVIlBQUFqV+/fnJwcLD+0RwWFnbXc3399dc6cOCApJuPC//ll180YcIESTenj6WGKB06dFCdOnX0yiuv6PDhwypYsKBmz56t5OTkTJ3nbrp06aIvv/xSvXr10pYtW1SvXj0lJyfrt99+05dffqkNGzaoZs2aatq0qXUEUs+ePZWQkKC5c+eqUKFCaaYaBgQEaM6cOZowYYJ8fX1VqFAhNWrUSE2bNlXJkiXVvXt3DRkyRLlz59a8efPk6emp2NjYTNU7ZMgQrVmzRs8995y6deumgIAAJSYm6uDBg1q+fLliYmJUsGBBvfbaazp//rwaNWqk4sWL6+TJk/rggw9UrVo1m9EkmVG1atU7/rEo3ZzWU6ZMGYWEhOj06dNyd3fXihUr0oxASc+4ceP0ww8/6Nlnn5W3t7fOnDmj2bNnq3jx4jYLi99PZcuWVffu3bVnzx4VLlxY8+bN099//20TRA4fPtz6+Pp+/fopf/78WrBggU6cOKEVK1Zkan2satWqKXfu3Jo8ebLi4+Pl4OCgRo0aqW7duvLw8FDXrl3Vr18/WSwWffbZZ/c05bBMmTLKly+fPvroI7m5ucnFxUVPPPGESpUqpU8//VTNmzdXxYoV9corr6hYsWI6ffq0tmzZInd3d3399de6fPmyihcvrg4dOqhq1apydXXVd999pz179qS7JlBOat26tVq3bn3HfapWraquXbvqk08+sU6F3L17txYsWKA2bdpYpxN6enoqJCREEydO1HPPPacWLVpo3759WrduXZoRgZn9vqVnwoQJ2rRpk+rXr68333xTdnZ2+vjjj5WUlHTHtdpu9dNPP1l/L94qMDAw3e9Gz549NWvWLHXq1En9+/dX0aJFtWjRImsQmJ1pjnf63HTu3FmHDh3SxIkTtXv3br3wwgsqVaqUEhMTdejQIS1ZskRubm5p1u6Kj4/X559/Lkm6ceOGjhw5ojlz5sjJyUnDhw+/Yz13WgsNwGPEhCcBAgCA/0Dv3r2N2//VfvnyZWPgwIGGl5eXkSdPHsPPz8+YOnWqzWPVDeP/HmX++eefG35+foaDg4NRvXr1dB97n56uXbum+8hwpfNY8vPnzxvdu3c3ChQoYDg7OxsNGjQw9uzZk6nz3P5I+fRcu3bNmDx5slGxYkXDwcHB8PDwMAICAoywsDAjPj7eut+aNWuMKlWqGI6OjoaPj48xefJkY968eYYk48SJE9b9/vrrL+PZZ5813NzcDEk2j3P/+eefjSeeeMKwt7c3SpYsabz77rvWR6Lf2sedHn9++fJlY8SIEYavr69hb29vFCxY0Khbt64xbdo049q1a4ZhGMby5cuNpk2bGoUKFbKeq2fPnkZcXNxd75ky8Zj6sWPHGpKMs2fPWtsOHz5sNGnSxHB1dTUKFixo9OjRwzhw4ECan2nqsak2b95stG7d2vDy8jLs7e0NLy8vo1OnTsbRo0fvWuvt9+nEiROGJGPq1Kk2+23ZssWQZCxbtsym/dbH0d/e54YNG4wqVaoYDg4ORvny5dMcaxiGER0dbXTo0MHIly+f4ejoaNSuXdv45ptvMnXuVHPnzjVKly5t5M6d25Bk/Q5FRkYaderUMZycnAwvLy9j6NChxoYNG2z2MYyMP+Ndu3Y1vL29bdq++uoro0KFCoadnV2an8u+ffuMdu3aGQUKFDAcHBwMb29vIzg42Ni8ebNhGIaRlJRkDBkyxKhatarh5uZmuLi4GFWrVjVmz56d7nVl193uV6r0rvv69etGWFiYUapUKSNPnjxGiRIljBEjRhhXr1612S85OdkICwszihYtajg5ORmBgYHGoUOHDG9vb6Nr1642+2bm+2YYN783Y8eOtTl27969RlBQkOHq6mo4OzsbDRs2NHbs2JGp+5DR70dJxvjx46334NbfL4ZhGL///rvx7LPPGk5OToanp6cxePBgY8WKFYYk48cff7zj/TOMrH9uDMMwIiIijA4dOhhFixY18uTJY7i7uxs1a9Y0xo4dm+Z3ToMGDWyuxWKxGPnz5zdatWpl/Pzzzzb7pvf9TM+dfl8CeDRZDOM+rA4JAAAeaBaLRb17904z7Q942Pn4+KhSpUr65ptvzC4FyBEzZszQwIED9ccff6hYsWJmlwMA94w1pgAAAADgAfTvv//avL969ao+/vhj+fn5EUoBeGSwxhQAAAAAPIDatWunkiVLqlq1ata1nH777TctWrTI7NIAIMcQTAEAAADAAygoKEiffvqpFi1apOTkZFWoUEFLly7V888/b3ZpAJBjWGMKAAAAAAAApmCNKQAAAAAAAJiCYAoAAAAAAACmYI0p4DGWkpKiP//8U25ubrJYLGaXAwAAAAB4yBmGocuXL8vLy0u5ct19PBTBFPAY+/PPP1WiRAmzywAAAAAAPGJOnTql4sWL33U/gingMebm5ibp5i8Md3d3k6sBAAAAADzsLl26pBIlSlj/3rwbgingMZY6fc/d3Z1gCgAAAACQYzK7XAyLnwMAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUPJUPgNrXDVGe3PZmlwEAAAAASMe3B2aZXcJ/hhFTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAUAAAAAAABTEEwBAAAAAADAFARTAAAAAAAAMAXBFAAAAAAAAExBMAVkQmBgoAYMGGB2GQAAAAAAPFIIpoD76Nq1a2aXAAAAAADAA4NgCqYIDAxUv379NHToUOXPn19FihRRaGioJCkmJkYWi0X79++37n/x4kVZLBZFRERIkiIiImSxWLRhwwZVr15dTk5OatSokc6cOaN169bJ399f7u7u6ty5s65cuXJPtXbr1k1bt27VzJkzZbFYZLFYFBMTI0naunWrateuLQcHBxUtWlTDhw/XjRs3bK6zT58+GjBggAoWLKigoCBJ0rfffquyZcvKyclJDRs2VHh4uCwWiy5evChJCg0NVbVq1WzqmDFjhnx8fGzaPv30U/n7+8vR0VHly5fX7Nmz7+laAQAAAAC4n+zMLgCPrwULFmjQoEHatWuXdu7cqW7duqlevXry8/PLdB+hoaGaNWuWnJ2dFRwcrODgYDk4OGjx4sVKSEhQ27Zt9cEHH2jYsGHZrnPmzJk6evSoKlWqpHHjxkmSPD09dfr0abVo0ULdunXTwoUL9dtvv6lHjx5ydHS0hmyp1/nGG28oMjJSknTq1Cm1a9dOvXv31uuvv66ffvpJgwcPznJdixYt0pgxYzRr1ixVr15d+/btU48ePeTi4qKuXbume0xSUpKSkpKs7y9dupTl8wIAAAAAkFMIpmCaKlWqaOzYsZIkPz8/zZo1S5s3b85SMDVhwgTVq1dPktS9e3eNGDFC0dHRKl26tCSpQ4cO2rJlyz0FU3nz5pW9vb2cnZ1VpEgRa/vs2bNVokQJzZo1SxaLReXLl9eff/6pYcOGacyYMcqVK5f12qZMmWI97q233lKZMmU0ffp0SVK5cuV08OBBTZ48OUt1jR07VtOnT1e7du0kSaVKldLhw4f18ccfZxhMTZw4UWFhYVk6DwAAAAAA/xWm8sE0VapUsXlftGhRnTlzJtt9FC5cWM7OztZQKrUtq31mVlRUlJ588klZLBZrW7169ZSQkKA//vjD2hYQEJDmuCeeeMKm7cknn8zSuRMTExUdHa3u3bvL1dXV+powYYKio6MzPG7EiBGKj4+3vk6dOpWl8wIAAAAAkJMYMQXT5MmTx+a9xWJRSkqKdaSRYRjWbdevX79rHxaLJcM+zeTi4pLlY3LlymVz/ZLtPUhISJAkzZ07N03IlTt37gz7dXBwkIODQ5brAQAAAADgv8CIKTxwPD09JUlxcXHWtlsXQjeDvb29kpOTbdr8/f21c+dOmwApMjJSbm5uKl68eIZ9+fv7a/fu3TZtP/74o817T09P/fXXXzZ933oPChcuLC8vL/3+++/y9fW1eZUqVSo7lwgAAAAAwH1HMIUHjpOTk+rUqaNJkyYpKipKW7du1ahRo0ytycfHR7t27VJMTIzOnTunlJQUvfnmmzp16pT69u2r3377TV999ZXGjh2rQYMGWUd9padXr146duyYhgwZoiNHjmjx4sUKDw+32ScwMFBnz57VlClTFB0drQ8//FDr1q2z2ScsLEwTJ07U+++/r6NHj+rgwYOaP3++3n333f/iFgAAAAAAkOMIpvBAmjdvnm7cuKGAgAANGDBAEyZMMLWekJAQ5c6dWxUqVJCnp6diY2NVrFgxffvtt9q9e7eqVq2qXr16qXv37ncN0UqWLKkVK1Zo9erVqlq1qj766CO98847Nvv4+/tr9uzZ+vDDD1W1alXt3r1bISEhNvu89tpr+vTTTzV//nxVrlxZDRo0UHh4OCOmAAAAAAAPDYtx+0I2AO67iIgINWzYUBcuXFC+fPnu23kvXbqkvHnzqknFHsqT2/6+nRcAAAAAkHnfHphldgmZlvp3Znx8vNzd3e+6PyOmAAAAAAAAYAqeyofHQmxsrCpUqJDutitXrkiSnJ2d091++PBhlSxZ8j+rDQAAAACAxxXBFB4LXl5e2X6yn5eXV84Wk47AwEAxqxYAAAAA8LghmMJjwc7OTr6+vmaXAQAAAAAAbsEaUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADCFndkFADDfih3T5O7ubnYZAAAAAIDHDCOmAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJjCzuwCAJivQ/A7ypPHwewyAAAAAOChtvbrMLNLeOgwYgoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJi6R4GBgRowYIDZZTxwunXrpjZt2uRYf7/99pvq1KkjR0dHVatWLcf6BQAAAAAA5iGYeszkdGB0v4wdO1YuLi46cuSINm/ebHY5953FYtHq1avNLgMAAAAAgBxFMIWHQnR0tOrXry9vb28VKFAgW31cu3Yt3fbr16/fS2kAAAAAACCbTA2mAgMD1a9fPw0dOlT58+dXkSJFFBoaKkmKiYmRxWLR/v37rftfvHhRFotFERERkqSIiAhZLBZt2LBB1atXl5OTkxo1aqQzZ85o3bp18vf3l7u7uzp37qwrV67cc72JiYl6+eWX5erqqqJFi2r69Olp9klKSlJISIiKFSsmFxcXPfHEE9Z6JenkyZNq2bKlPDw85OLioooVK+rbb7+1bl+zZo38/Pzk6Oiohg0basGCBbJYLLp48aIk6Z9//lGnTp1UrFgxOTs7q3LlylqyZIlNDcuXL1flypXl5OSkAgUKqEmTJkpMTFRoaKgWLFigr776ShaLxeZenjp1SsHBwcqXL5/y58+v1q1bKyYmJlP3JTk5WYMGDVK+fPlUoEABDR06VIZh2Oyzfv161a9f37rPc889p+jo6Ez1b7FY9PPPP2vcuHGyWCzWz8jdak4dHfb222/Ly8tL5cqVs36uvvjiCzVo0ECOjo5atGhRpu5rYGCg+vbtqwEDBsjDw0OFCxfW3LlzlZiYqFdeeUVubm7y9fXVunXrbI47dOiQmjdvLldXVxUuXFhdunTRuXPnbPrN6HsgST4+PpKktm3bymKxWN9HR0erdevWKly4sFxdXVWrVi199913mbqnAAAAAAA8CEwfMbVgwQK5uLho165dmjJlisaNG6dNmzZlqY/Q0FDNmjVLO3bssIYVM2bM0OLFi7V27Vpt3LhRH3zwwT3XOmTIEG3dulVfffWVNm7cqIiICO3du9dmnz59+mjnzp1aunSpfvnlF3Xs2FHNmjXTsWPHJEm9e/dWUlKSfvjhBx08eFCTJ0+Wq6urJOnEiRPq0KGD2rRpowMHDqhnz54aOXKkTf9Xr15VQECA1q5dq0OHDun1119Xly5dtHv3bklSXFycOnXqpFdffVVRUVGKiIhQu3btZBiGQkJCFBwcrGbNmikuLk5xcXGqW7eurl+/rqCgILm5uWnbtm2KjIyUq6urmjVrluEoo1tNnz5d4eHhmjdvnrZv367z589r1apVNvskJiZq0KBB+umnn7R582blypVLbdu2VUpKyl37j4uLU8WKFTV48GDFxcUpJCQk0zVv3rxZR44c0aZNm/TNN99Y24cPH67+/fsrKipKQUFBd72vqRYsWKCCBQtq9+7d6tu3r9544w117NhRdevW1d69e9W0aVN16dLFGoRevHhRjRo1UvXq1fXTTz9p/fr1+vvvvxUcHJym34y+B3v27JEkzZ8/X3Fxcdb3CQkJatGihTZv3qx9+/apWbNmatmypWJjY+96TwEAAAAAeBBYjNuHttxHgYGBSk5O1rZt26xttWvXVqNGjdSrVy+VKlVK+/btsy52ffHiRXl4eGjLli0KDAxURESEGjZsqO+++06NGzeWJE2aNEkjRoxQdHS0SpcuLUnq1auXYmJitH79+mzXmpCQoAIFCujzzz9Xx44dJUnnz59X8eLF9frrr2vGjBmKjY1V6dKlFRsbKy8vL+uxTZo0Ue3atfXOO++oSpUqat++vcaOHZvmHMOHD9fatWt18OBBa9uoUaP09ttv68KFC8qXL1+6tT333HMqX768pk2bpr179yogIEAxMTHy9vZOs2+3bt108eJFm/WKPv/8c02YMEFRUVGyWCySbk57y5cvn1avXq2mTZve8d54eXlp4MCBGjJkiCTpxo0bKlWqlAICAjJcF+ncuXPy9PTUwYMHValSpTv2L0nVqlVTmzZtrCOJMlNzt27dtH79esXGxsre3l7SzZF4pUqV0owZM9S/f/87nvPW+yql/bwmJycrb968ateunRYuXChJ+uuvv1S0aFHt3LlTderU0YQJE7Rt2zZt2LDB2u8ff/yhEiVK6MiRIypbtuwdvweTJk2SdHPU2KpVq+66PlilSpXUq1cv9enTJ93tSUlJSkpKsr6/dOmSSpQooWeChilPHoc79g0AAAAAuLO1X4eZXYLpLl26pLx58yo+Pl7u7u533d/uPtR0R1WqVLF5X7RoUZ05cybbfRQuXFjOzs7WUCq17faRL1kVHR2ta9eu6YknnrC25c+fX+XKlbO+P3jwoJKTk1W2bFmbY5OSkqzrIvXr109vvPGGNm7cqCZNmqh9+/bW+o8cOaJatWrZHFu7dm2b98nJyXrnnXf05Zdf6vTp07p27ZqSkpLk7OwsSapataoaN26sypUrKygoSE2bNlWHDh3k4eGR4bUdOHBAx48fl5ubm0371atX7zrdLj4+XnFxcTb3xc7OTjVr1rSZznfs2DGNGTNGu3bt0rlz56wjpWJjYzMVTGW35sqVK1tDqVvVrFnT5v3d7muqWz9ruXPnVoECBVS5cmVrW+HChSXJ+hk+cOCAtmzZYh0Vd6vo6GjrZyU734OEhASFhoZq7dq1iouL040bN/Tvv//eccTUxIkTFRbGL0oAAAAAwIPB9GAqT548Nu8tFotSUlKUK9fNWYa3hhsZLVJ9ax8WiyXDPv9rCQkJyp07t37++Wflzp3bZltqMPHaa68pKCjIOsVw4sSJmj59uvr27Zupc0ydOlUzZ87UjBkzVLlyZbm4uGjAgAHW6Wu5c+fWpk2btGPHDusUxpEjR2rXrl0qVapUhnUHBARo0aJFabZ5enpm5RZkqGXLlvL29tbcuXPl5eWllJQUVapUKVNTBdOT2ZpdXFzSPf729rvd11TpfbZu//xJsn7eEhIS1LJlS02ePDlNDUWLFr1jv3f7zIaEhGjTpk2aNm2afH195eTkpA4dOtzxno4YMUKDBg2yvk8dMQUAAAAAgBlMD6YykhouxMXFqXr16pJksxD6/VamTBnlyZNHu3btUsmSJSVJFy5c0NGjR9WgQQNJUvXq1ZWcnKwzZ87oqaeeyrCvEiVKqFevXurVq5dGjBihuXPnqm/fvipXrpzNQujS/60vlCoyMlKtW7fWSy+9JOlmAHL06FFVqFDBuo/FYlG9evVUr149jRkzRt7e3lq1apUGDRoke3t7JScn2/RZo0YNffHFFypUqFCmhtndKm/evCpatKh27dqlp59+WtLNqXw///yzatSoIenmgu1HjhzR3Llzrfdl+/btWTrP7e6l5vRk5r5mt84VK1bIx8dHdnbZ/7rlyZMnzc8tMjJS3bp1U9u2bSXdDMHutmC9g4ODHByYsgcAAAAAeDCYvvh5RpycnFSnTh1NmjRJUVFR2rp1q0aNGmVaPa6ururevbuGDBmi77//XocOHVK3bt2sI7skqWzZsnrxxRf18ssva+XKlTpx4oR2796tiRMnau3atZKkAQMGaMOGDTpx4oT27t2rLVu2yN/fX5LUs2dP/fbbbxo2bJiOHj2qL7/8UuHh4ZL+bySOn5+fdURUVFSUevbsqb///ttaw65du/TOO+/op59+UmxsrFauXKmzZ89az+Hj46NffvlFR44c0blz53T9+nW9+OKLKliwoFq3bq1t27bpxIkTioiIUL9+/fTHH3/c9d70799fkyZN0urVq/Xbb7/pzTfftD5FUJI8PDxUoEABffLJJzp+/Li+//57m1E72XGvNd/ubvc1u3r37q3z58+rU6dO2rNnj6Kjo7Vhwwa98soraYKmO/Hx8dHmzZv1119/6cKFC9aaV65cqf379+vAgQPq3LnzfRkZCAAAAABATnlggylJmjdvnm7cuKGAgAANGDBAEyZMMLWeqVOn6qmnnlLLli3VpEkT1a9fXwEBATb7zJ8/Xy+//LIGDx6scuXKqU2bNtqzZ491lFVycrJ69+4tf39/NWvWTGXLltXs2bMlSaVKldLy5cu1cuVKValSRXPmzLE+lS91lMuoUaNUo0YNBQUFKTAwUEWKFLFZENvd3V0//PCDWrRoobJly2rUqFGaPn26mjdvLknq0aOHypUrp5o1a8rT01ORkZFydnbWDz/8oJIlS6pdu3by9/dX9+7ddfXq1UyNRho8eLC6dOmirl276sknn5Sbm5t1FI8k5cqVS0uXLtXPP/+sSpUqaeDAgZo6dWr2fxDSPdd8u7vd1+zy8vJSZGSkkpOT1bRpU1WuXFkDBgxQvnz5bELNu5k+fbo2bdqkEiVKWEcQvvvuu/Lw8FDdunXVsmVLBQUFWUepAQAAAADwMDD1qXy4u7ffflsfffSRTp06ZXYpeASlPi2Bp/IBAAAAwL3jqXwP4VP5YGv27NmqVauWChQooMjISE2dOlV9+vQxuywAAAAAAIAc91gFU7GxsRkuZn3lyhVJN6eIpefw4cPW6Xj/pWPHjmnChAk6f/68SpYsqcGDB2vEiBH/+XnvJPWJgulZt27dHRd6z4x33nlH77zzTrrbnnrqKa1bt+6e+gcAAAAAAA+mx2oq340bN+761LKM3OtT1R5mx48fz3BbsWLF5OTkdE/9nz9/XufPn093m5OTk4oVK3ZP/SNjTOUDAAAAgJzDVD6m8t2RnZ2dfH19zS7jofNf37P8+fMrf/78/+k5AAAAAADAg+eBfiofAAAAAAAAHl0EUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBR2ZhcAwHzLv3xL7u7uZpcBAAAAAHjMMGIKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKO7MLAGC+Z3tNlp29o9llAAAAAHiIbQkfbXYJeAgxYgoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYOoRYLFYtHr16vvWX0xMjCwWi/bv339P5+nWrZvatGlzT308qEJDQ1WtWrX7ft7AwEANGDDgvp8XAAAAAIDsIJhCGnFxcWrevLnZZdwXERERslgsunjxYo72GxISos2bN+donwAAAAAAPGrszC4AD54iRYqYXcI9MwxDycnJsrMz5yPu6uoqV1dXU84NAAAAAMDD4pEbMRUYGKh+/fpp6NChyp8/v4oUKaLQ0FBJ6U9Bu3jxoiwWiyIiIiT93wiaDRs2qHr16nJyclKjRo105swZrVu3Tv7+/nJ3d1fnzp115cqVe6r1k08+kZeXl1JSUmzaW7durVdffdX6/quvvlKNGjXk6Oio0qVLKywsTDdu3Miw34MHD6pRo0ZycnJSgQIF9PrrryshIcFmn3nz5qlixYpycHBQ0aJF1adPH+u226fy7d69W9WrV5ejo6Nq1qypffv22fSVnJys7t27q1SpUnJyclK5cuU0c+bMNPsMGjRI+fLlU4ECBTR06FAZhmGzT0pKiiZOnGjtp2rVqlq+fPmdb+L/l/pzW7dunQICAuTg4KDt27crKSlJ/fr1U6FCheTo6Kj69etrz549km5+Hho2bChJ8vDwkMViUbdu3SRJ69evV/369a31Pvfcc4qOjrY55x9//KFOnTopf/78cnFxUc2aNbVr1y5JaafypaSkaNy4cSpevLgcHBxUrVo1rV+/3ro99bO5cuVKNWzYUM7Ozqpatap27txp3eeff/5Rp06dVKxYMTk7O6ty5cpasmRJpu4PAAAAAAAPokcumJKkBQsWyMXFRbt27dKUKVM0btw4bdq0KUt9hIaGatasWdqxY4dOnTql4OBgzZgxQ4sXL9batWu1ceNGffDBB/dUZ8eOHfXPP/9oy5Yt1rbz589r/fr1evHFFyVJ27Zt08svv6z+/fvr8OHD+vjjjxUeHq6333473T4TExMVFBQkDw8P7dmzR8uWLdN3331nEzzNmTNHvXv31uuvv66DBw9qzZo18vX1Tbe/hIQEPffcc6pQoYJ+/vlnhYaGKiQkxGaflJQUFS9eXMuWLdPhw4c1ZswYvfXWW/ryyy+t+0yfPl3h4eGaN2+etm/frvPnz2vVqlU2/UycOFELFy7URx99pF9//VUDBw7USy+9pK1bt2b6ng4fPlyTJk1SVFSUqlSpoqFDh2rFihVasGCB9u7dK19fXwUFBen8+fMqUaKEVqxYIUk6cuSI4uLirIFaYmKiBg0apJ9++kmbN29Wrly51LZtW2uImJCQoAYNGuj06dNas2aNDhw4oKFDh6YJGVPNnDlT06dP17Rp0/TLL78oKChIrVq10rFjx2z2GzlypEJCQrR//36VLVtWnTp1soaQV69eVUBAgNauXatDhw7p9ddfV5cuXbR79+5M3x8AAAAAAB4kj+RUvipVqmjs2LGSJD8/P82aNUubN2+Wn59fpvuYMGGC6tWrJ0nq3r27RowYoejoaJUuXVqS1KFDB23ZskXDhg3Ldp0eHh5q3ry5Fi9erMaNG0uSli9froIFC1pH8oSFhWn48OHq2rWrJKl06dIaP368hg4dar3GWy1evFhXr17VwoUL5eLiIkmaNWuWWrZsqcmTJ6tw4cKaMGGCBg8erP79+1uPq1WrVro1Ll68WCkpKfrf//4nR0dHVaxYUX/88YfeeOMN6z558uRRWFiY9X2pUqW0c+dOffnllwoODpYkzZgxQyNGjFC7du0kSR999JE2bNhgPSYpKUnvvPOOvvvuOz355JPWa92+fbs+/vhjNWjQIFP3dNy4cXrmmWck3QyX5syZo/DwcOuaWXPnztWmTZv0v//9T0OGDFH+/PklSYUKFVK+fPms/bRv396m33nz5snT01OHDx9WpUqVtHjxYp09e1Z79uyx9pFRuCdJ06ZN07Bhw/TCCy9IkiZPnqwtW7ZoxowZ+vDDD637hYSE6Nlnn5V082dfsWJFHT9+XOXLl1exYsVsQsG+fftqw4YN+vLLL1W7du1M3Z+kpCQlJSVZ31+6dClTxwEAAAAA8F94JEdMValSxeZ90aJFdebMmWz3UbhwYTk7O1tDqdS2rPaZnhdffFErVqywhgWLFi3SCy+8oFy5bv5oDhw4oHHjxlnXLHJ1dVWPHj0UFxeX7lTCqKgoVa1a1RpKSVK9evWUkpKiI0eO6MyZM/rzzz+tQdjdpI48cnR0tLalBke3+vDDDxUQECBPT0+5urrqk08+UWxsrCQpPj5ecXFxeuKJJ6z729nZqWbNmtb3x48f15UrV/TMM8/YXOvChQvTTKG7k1v7jI6O1vXr160Bo3QzRKtdu7aioqLu2M+xY8fUqVMnlS5dWu7u7vLx8ZEk6zXt379f1atXt4ZSd3Lp0iX9+eefNnVIN38ut9dx6+euaNGikmT9nCUnJ2v8+PGqXLmy8ufPL1dXV23YsMFaU2ZMnDhRefPmtb5KlCiR6WMBAAAAAMhpj+SIqTx58ti8t1gsSklJsYY9t65tdP369bv2YbFYMuzzXrVs2VKGYWjt2rWqVauWtm3bpvfee8+6PSEhQWFhYdaRRre6NSzKLCcnp3uqNz1Lly5VSEiIpk+frieffFJubm6aOnWqdb2lzEhdA2vt2rUqVqyYzTYHB4dM93NrIHcvWrZsKW9vb82dO9e6DlilSpV07do1Sf/NfZTSfu4kWT9nU6dO1cyZMzVjxgxVrlxZLi4uGjBggLWmzBgxYoQGDRpkfX/p0iXCKQAAAACAaR7JEVMZ8fT0lCTFxcVZ225dCN0Mjo6OateunRYtWqQlS5aoXLlyqlGjhnV7jRo1dOTIEfn6+qZ5pQZtt/L399eBAweUmJhobYuMjFSuXLlUrlw5ubm5ycfHR5s3b85Uff7+/vrll1909epVa9uPP/5os09kZKTq1q2rN998U9WrV5evr6/NKKe8efOqaNGiNkHVjRs39PPPP1vfV6hQQQ4ODoqNjU1zndkNTsqUKSN7e3tFRkZa265fv649e/aoQoUKkiR7e3tJN0cjpfrnn3905MgRjRo1So0bN5a/v78uXLhg03eVKlW0f/9+nT9//q51uLu7y8vLy6YO6eZ9S60jMyIjI9W6dWu99NJLqlq1qkqXLq2jR49m+njpZsjn7u5u8wIAAAAAwCyP5IipjDg5OalOnTqaNGmSSpUqpTNnzmjUqFFml6UXX3xRzz33nH799Ve99NJLNtvGjBmj5557TiVLllSHDh2UK1cuHThwQIcOHdKECRPS7Wvs2LHq2rWrQkNDdfbsWfXt21ddunRR4cKFJd1c2L1Xr14qVKiQmjdvrsuXLysyMlJ9+/ZN01/nzp01cuRI9ejRQyNGjFBMTIymTZtms4+fn58WLlyoDRs2qFSpUvrss8+0Z88elSpVyrpP//79NWnSJPn5+al8+fJ69913dfHiRet2Nzc3hYSEaODAgUpJSVH9+vUVHx+vyMhIubu7W9fYygoXFxe98cYb1rWkSpYsqSlTpujKlSvq3r27JMnb21sWi0XffPONWrRoIScnJ3l4eKhAgQL65JNPVLRoUcXGxmr48OE2fXfq1EnvvPOO2rRpo4kTJ6po0aLat2+fvLy80p3qOGTIEI0dO1ZlypRRtWrVNH/+fO3fv1+LFi3K9PX4+flp+fLl2rFjhzw8PPTuu+/q77//zlK4BQAAAADAg+SxGjEl3VzE+saNGwoICNCAAQPSDXfut0aNGil//vw6cuSIOnfubLMtKChI33zzjTZu3KhatWqpTp06eu+99+Tt7Z1uX87OztqwYYPOnz+vWrVqqUOHDmrcuLFmzZpl3adr166aMWOGZs+erYoVK+q5555L83S4VK6urvr666918OBBVa9eXSNHjtTkyZNt9unZs6fatWun559/Xk888YT++ecfvfnmmzb7DB48WF26dFHXrl2t0/3atm1rs8/48eM1evRoTZw4Uf7+/mrWrJnWrl1rE3Bl1aRJk9S+fXt16dJFNWrU0PHjx7VhwwZ5eHhIkooVK2ZdYL5w4cLq06ePcuXKpaVLl+rnn39WpUqVNHDgQE2dOtWmX3t7e23cuFGFChVSixYtVLlyZU2aNEm5c+dOt45+/fpp0KBBGjx4sCpXrqz169drzZo1WVqQf9SoUapRo4aCgoIUGBioIkWKqE2bNtm+NwAAAAAAmM1i3LrgEoDHyqVLl5Q3b17V7/SW7OyzvmYZAAAAAKTaEj7a7BLwAEj9OzM+Pj5Ty8c8diOmAAAAAAAA8GAgmLpHsbGxcnV1TfeVK1cu5cqVK8PtsbGxZpf/0OjVq1eG97FXr15mlwcAAAAAALLhsVr8/L/g5eWV7Sf7eXl55Wwxj7Bx48YpJCQk3W08WQ4AAAAAgIcTwdQ9srOzk6+vr9llPPIKFSqkQoUKmV0GAAAAAADIQUzlAwAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCnszC4AgPnWfjRM7u7uZpcBAAAAAHjMMGIKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKO7MLAGC+RiMmK7eDo9llAAAA4CG3693RZpcA4CHDiCkAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYQqYEBgZqwIABZpdxX4SGhqpatWpmlwEAAAAAwCOPYAqPjWvXrt3X8xmGoRs3btzXc5p5XgAAAAAAsopgyiSBgYHq16+fhg4dqvz586tIkSIKDQ2VJMXExMhisWj//v3W/S9evCiLxaKIiAhJUkREhCwWizZs2KDq1avLyclJjRo10pkzZ7Ru3Tr5+/vL3d1dnTt31pUrV+6p1m7dumnr1q2aOXOmLBaLLBaLYmJiJEmHDh1S8+bN5erqqsKFC6tLly46d+6czXX27dtXAwYMkIeHhwoXLqy5c+cqMTFRr7zyitzc3OTr66t169ZZj0m9trVr16pKlSpydHRUnTp1dOjQIZu6tm/frqeeekpOTk4qUaKE+vXrp8TEROt2Hx8fjR8/Xi+//LLc3d31+uuvS5KGDRumsmXLytnZWaVLl9bo0aN1/fp1SVJ4eLjCwsJ04MAB67WGh4dn6Weybt06BQQEyMHBQdu3b1d0dLRat26twoULy9XVVbVq1dJ3332X6fv/2WefqWbNmnJzc1ORIkXUuXNnnTlzJs39uv28AAAAAAA86AimTLRgwQK5uLho165dmjJlisaNG6dNmzZlqY/Q0FDNmjVLO3bs0KlTpxQcHKwZM2Zo8eLFWrt2rTZu3KgPPvjgnuqcOXOmnnzySfXo0UNxcXGKi4tTiRIldPHiRTVq1EjVq1fXTz/9pPXr1+vvv/9WcHBwmussWLCgdu/erb59++qNN95Qx44dVbduXe3du1dNmzZVly5d0gRoQ4YM0fTp07Vnzx55enqqZcuW1gApOjpazZo1U/v27fXLL7/oiy++0Pbt29WnTx+bPqZNm6aqVatq3759Gj16tCTJzc1N4eHhOnz4sGbOnKm5c+fqvffekyQ9//zzGjx4sCpWrGi91ueffz5L92v48OGaNGmSoqKiVKVKFSUkJKhFixbavHmz9u3bp2bNmqlly5aKjY3NVH/Xr1/X+PHjdeDAAa1evVoxMTHq1q3bXc+bnqSkJF26dMnmBQAAAACAWezMLuBxVqVKFY0dO1aS5Ofnp1mzZmnz5s3y8/PLdB8TJkxQvXr1JEndu3fXiBEjFB0drdKlS0uSOnTooC1btmjYsGHZrjNv3ryyt7eXs7OzihQpYm2fNWuWqlevrnfeecfaNm/ePJUoUUJHjx5V2bJlJUlVq1bVqFGjJEkjRozQpEmTVLBgQfXo0UOSNGbMGM2ZM0e//PKL6tSpY+1r7NixeuaZZyTdDLeKFy+uVatWKTg4WBMnTtSLL75oXffKz89P77//vho0aKA5c+bI0dFRktSoUSMNHjzY5npSa5FujqoKCQnR0qVLNXToUDk5OcnV1VV2dnY215oV48aNs9YtSfnz51fVqlWt78ePH69Vq1ZpzZo1aYK09Lz66qvWfy5durTef/991apVSwkJCXJ1dc3wvOmZOHGiwsLCsnI5AAAAAAD8ZxgxZaLbR7UULVrUZopWVvsoXLiwdXrarW1Z7TOzDhw4oC1btsjV1dX6Kl++vKSbI5rSqzF37twqUKCAKleubFOjpDR1Pvnkk9Z/zp8/v8qVK6eoqCjrucPDw23OHRQUpJSUFJ04ccJ6XM2aNdPU/cUXX6hevXoqUqSIXF1dNWrUqEyPXsqM28+ZkJCgkJAQ+fv7K1++fHJ1dVVUVFSmz/nzzz+rZcuWKlmypNzc3NSgQQNJSnN8etd6uxEjRig+Pt76OnXqVCavCgAAAACAnMeIKRPlyZPH5r3FYlFKSopy5bqZFxqGYd2WOoXtTn1YLJYM+/wvJCQkqGXLlpo8eXKabUWLFk23xvTqtFgskpSlOhMSEtSzZ0/169cvzbaSJUta/9nFxcVm286dO/Xiiy8qLCxMQUFByps3r5YuXarp06ff8XxZ+Zncfs6QkBBt2rRJ06ZNk6+vr5ycnNShQ4dMLcaemJiooKAgBQUFadGiRfL09FRsbKyCgoLSHH/7edPj4OAgBweHu+4HAAAAAMD9QDD1APL09JQkxcXFqXr16pJks+i2Gezt7ZWcnGzTVqNGDa1YsUI+Pj6ys8v5j9KPP/5oDZkuXLigo0ePyt/f33ruw4cPy9fXN0t97tixQ97e3ho5cqS17eTJkzb7pHet9/IziYyMVLdu3dS2bVtJN0O11MXj7+a3337TP//8o0mTJqlEiRKSpJ9++ilTxwIAAAAA8KBjKt8DyMnJSXXq1LEuZL1161abdZHM4OPjo127dikmJkbnzp1TSkqKevfurfPnz6tTp07as2ePoqOjtWHDBr3yyitpgp3sGDdunDZv3qxDhw6pW7duKliwoNq0aSPp5pP1duzYoT59+mj//v06duyYvvrqq7uu2eTn56fY2FgtXbpU0dHRev/997Vq1ao013rixAnt379f586dU1JS0j39TPz8/LRy5Urt379fBw4cUOfOnTM9OqxkyZKyt7fXBx98oN9//11r1qzR+PHjM3UsAAAAAAAPOoKpB9S8efN048YNBQQEaMCAAZowYYKp9YSEhCh37tyqUKGCdTqZl5eXIiMjlZycrKZNm6py5coaMGCA8uXLZ536di8mTZqk/v37KyAgQH/99Ze+/vpr2dvbS7q5btXWrVt19OhRPfXUU6pevbrGjBkjLy+vO/bZqlUrDRw4UH369FG1atW0Y8cO69P6UrVv317NmjVTw4YN5enpqSVLlkjK/s/k3XfflYeHh+rWrauWLVsqKChINWrUyNSxnp6eCg8P17Jly1ShQgVNmjRJ06ZNy9SxAAAAAAA86CzGrYvmAA+AiIgINWzYUBcuXFC+fPnMLueRdunSJeXNm1cBb76l3A6OZpcDAACAh9yud0fffScAj7TUvzPj4+Pl7u5+1/0ZMQUAAAAAAABTsPj5YyI2NlYVKlRId9uVK1ckSc7OzuluP3z4sM2T7pBztm3bpubNm2e4PSEh4T5WAwAAAADA/UUw9Zjw8vLK9pP97rZuU04LDAzU4zLDtGbNmqY/cREAAAAAALMQTD0m7Ozs5Ovra3YZuI2TkxM/FwAAAADAY4s1pgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCnszC4AgPm+nzhM7u7uZpcBAAAAAHjMMGIKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKO7MLAGC+elMmKrejg9llAAAAPFD2jwo1uwQAeOQxYgoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJgi28HUZ599pnr16snLy0snT56UJM2YMUNfffVVjhUHAAAAAACAR1e2gqk5c+Zo0KBBatGihS5evKjk5GRJUr58+TRjxoycrA8AAAAAAACPqGwFUx988IHmzp2rkSNHKnfu3Nb2mjVr6uDBgzlWHAAAAAAAAB5d2QqmTpw4oerVq6dpd3BwUGJi4j0XBQAAAAAAgEdftoKpUqVKaf/+/Wna169fL39//3utCQAAAAAAAI8Bu+wcNGjQIPXu3VtXr16VYRjavXu3lixZookTJ+rTTz/N6RoBAAAAAADwCMpWMPXaa6/JyclJo0aN0pUrV9S5c2d5eXlp5syZeuGFF3K6RgAAAAAAADyCshxM3bhxQ4sXL1ZQUJBefPFFXblyRQkJCSpUqNB/UR8AAAAAAAAeUVleY8rOzk69evXS1atXJUnOzs6EUgAAAAAAAMiybC1+Xrt2be3bty+nawEAAAAAAMBjJFtrTL355psaPHiw/vjjDwUEBMjFxcVme5UqVXKkOAAAAAAAADy6shVMpS5w3q9fP2ubxWKRYRiyWCxKTk7OmeoAAAAAAADwyMpWMHXixImcrgMAAAAAAACPmWwFU97e3jldBwAAAAAAAB4z2QqmFi5ceMftL7/8craKAQAAAAAAwOMjW8FU//79bd5fv35dV65ckb29vZydnQmmAAAAAAAAcFe5snPQhQsXbF4JCQk6cuSI6tevryVLluR0jQAAAAAAAHgEZSuYSo+fn58mTZqUZjQVAAAAAAAAkJ4cC6Ykyc7OTn/++WdOdvlICQwM1IABA8wu474IDQ1VtWrVzC4DAAAAAAA8wLK1xtSaNWts3huGobi4OM2aNUv16tXLkcLwYLp27Zrs7e3v2/kMw1BycrLs7LL1Ub0n169fV548ee77eQEAAAAAeFxka8RUmzZtbF7t2rVTaGioqlSponnz5uV0jRkKDAxUv379NHToUOXPn19FihRRaGioJCkmJkYWi0X79++37n/x4kVZLBZFRERIkiIiImSxWLRhwwZVr15dTk5OatSokc6cOaN169bJ399f7u7u6ty5s65cuXJPtXbr1k1bt27VzJkzZbFYZLFYFBMTI0k6dOiQmjdvLldXVxUuXFhdunTRuXPnbK6zb9++GjBggDw8PFS4cGHNnTtXiYmJeuWVV+Tm5iZfX1+tW7fOekzqta1du1ZVqlSRo6Oj6tSpo0OHDtnUtX37dj311FNycnJSiRIl1K9fPyUmJlq3+/j4aPz48Xr55Zfl7u6u119/XZI0bNgwlS1bVs7OzipdurRGjx6t69evS5LCw8MVFhamAwcOWK81PDw8Sz+TdevWKSAgQA4ODtq+fbuio6PVunVrFS5cWK6urqpVq5a+++67TN//1Ovo1KmTXFxcVKxYMX344Yc2+1gsFs2ZM0etWrWSi4uL3n77bUnSnDlzVKZMGdnb26tcuXL67LPPbI67ePGievbsqcKFC8vR0VGVKlXSN998k+l7PHv2bPn5+cnR0VGFCxdWhw4drNuWL1+uypUry8nJSQUKFFCTJk2sx6akpGjcuHEqXry4HBwcVK1aNa1fvz7T9wQAAAAAALNlK5hKSUmxeSUnJ+uvv/7S4sWLVbRo0Zyu8Y4WLFggFxcX7dq1S1OmTNG4ceO0adOmLPURGhqqWbNmaceOHTp16pSCg4M1Y8YMLV68WGvXrtXGjRv1wQcf3FOdM2fO1JNPPqkePXooLi5OcXFxKlGihC5evKhGjRqpevXq+umnn7R+/Xr9/fffCg4OTnOdBQsW1O7du9W3b1+98cYb6tixo+rWrau9e/eqadOm6tKlS5oAbciQIZo+fbr27NkjT09PtWzZ0hogRUdHq1mzZmrfvr1++eUXffHFF9q+fbv69Olj08e0adNUtWpV7du3T6NHj5Ykubm5KTw8XIcPH9bMmTM1d+5cvffee5Kk559/XoMHD1bFihWt1/r8889n6X4NHz5ckyZNUlRUlKpUqaKEhAS1aNFCmzdv1r59+9SsWTO1bNlSsbGxme5z6tSp1usYPny4+vfvn+azEhoaqrZt2+rgwYN69dVXtWrVKvXv31+DBw/WoUOH1LNnT73yyivasmWLpJvfhebNmysyMlKff/65Dh8+rEmTJil37tyZusc//fST+vXrp3HjxunIkSNav369nn76aUlSXFycOnXqpFdffVVRUVGKiIhQu3btZBiGpJufqenTp2vatGn65ZdfFBQUpFatWunYsWMZ3oOkpCRdunTJ5gUAAAAAgFksRupfuVkwbtw4hYSEyNnZ2ab933//1dSpUzVmzJgcK/BOAgMDlZycrG3btlnbateurUaNGqlXr14qVaqU9u3bZ13r6OLFi/Lw8NCWLVsUGBioiIgINWzYUN99950aN24sSZo0aZJGjBih6OholS5dWpLUq1cvxcTE3PNolMDAQFWrVk0zZsywtk2YMEHbtm3Thg0brG1//PGHSpQooSNHjqhs2bJprjM5OVl58+ZVu3bttHDhQknSX3/9paJFi2rnzp2qU6eO9dqWLl1qDYXOnz+v4sWLKzw8XMHBwXrttdeUO3duffzxx9Zzb9++XQ0aNFBiYqIcHR3l4+Oj6tWra9WqVXe8tmnTpmnp0qX66aefJN0MeFavXm0zOiomJibTP5PVq1erdevWdzxnpUqV1KtXrzRBWnp8fHzk7+9vM6rshRde0KVLl/Ttt99KujliasCAAdaATZLq1aunihUr6pNPPrG2BQcHKzEx0RpaNm/eXFFRUSpbtmya897tHn/77bd65ZVX9Mcff8jNzc3m2L179yogIEAxMTHy9vZO03exYsXUu3dvvfXWW9a22rVrq1atWmlGg6UKDQ1VWFhYmvZKI4crt6NDuscAAAA8rvaPCjW7BAB46Fy6dEl58+ZVfHy83N3d77p/tkZMhYWFKSEhIU37lStX0v2j979UpUoVm/dFixbVmTNnst1H4cKFrdPTbm3Lap+ZdeDAAW3ZskWurq7WV/ny5SXdHG2TXo25c+dWgQIFVLlyZZsaJaWp88knn7T+c/78+VWuXDlFRUVZzx0eHm5z7qCgIKWkpOjEiRPW42rWrJmm7i+++EL16tVTkSJF5OrqqlGjRmVp9NLd3H7OhIQEhYSEyN/fX/ny5ZOrq6uioqKydM5b70Xq+9R7kdF5o6Ki0qybVq9ePetx+/fvV/HixdMNpaS73+NnnnlG3t7eKl26tLp06aJFixZZR71VrVpVjRs3VuXKldWxY0fNnTtXFy5ckHTzi/7nn3/esbb0jBgxQvHx8dbXqVOnMtwXAAAAAID/WrZWlDYMQxaLJU37gQMHlD9//nsuKituX5zaYrEoJSVFuXLdzNxuHRCWOoXtTn1YLJYM+/wvJCQkqGXLlpo8eXKabbdOi0yvptvrlpSlOhMSEtSzZ0/169cvzbaSJUta/9nFxcVm286dO/Xiiy8qLCxMQUFByps3r5YuXarp06ff8XxZ+Zncfs6QkBBt2rRJ06ZNk6+vr5ycnNShQwddu3btzheZRbef926cnJzuuP1u99je3l579+5VRESENm7cqDFjxig0NFR79uxRvnz5tGnTJu3YscM6nXTkyJHatWuXChQokKU6Uzk4OMjBgZFRAAAAAIAHQ5aCKQ8PD+ti1mXLlrUJp5KTk5WQkKBevXrleJHZ4enpKenmOj3Vq1eXJJtpZWawt7dXcnKyTVuNGjW0YsUK+fj4/CdPnvvxxx+tIdOFCxd09OhR+fv7W899+PBh+fr6ZqnPHTt2yNvbWyNHjrS2nTx50maf9K71Xn4mkZGR6tatm9q2bSvpZuCTunh8Zv34449p3qfei4z4+/srMjJSXbt2tamlQoUKkm6OZPvjjz909OjRdEdNZeYe29nZqUmTJmrSpInGjh2rfPny6fvvv1e7du1ksVhUr1491atXT2PGjJG3t7dWrVqlQYMGycvLS5GRkWrQoIFNbbVr187U/QAAAAAAwGxZSkJmzJghwzD06quvKiwsTHnz5rVus7e3l4+PT5rpUmZxcnJSnTp1NGnSJJUqVUpnzpzRqFGjTK3Jx8dHu3btUkxMjFxdXZU/f3717t1bc+fOVadOnaxPFzx+/LiWLl2qTz/91LqIdnaNGzdOBQoUUOHChTVy5EgVLFhQbdq0kXTzyXp16tRRnz599Nprr8nFxUWHDx/Wpk2bNGvWrAz79PPzU2xsrJYuXapatWpp7dq1adag8vHx0YkTJ6xT3dzc3O7pZ+Ln56eVK1eqZcuWslgsGj16dJZHsUVGRmrKlClq06aNNm3apGXLlmnt2rV3PGbIkCEKDg5W9erV1aRJE3399ddauXKl9YmADRo00NNPP6327dvr3Xffla+vr3777TdZLBY1a9bsrvf4m2++0e+//66nn35aHh4e+vbbb5WSkqJy5cpp165d2rx5s5o2bapChQpp165dOnv2rDVMGzJkiMaOHasyZcqoWrVqmj9/vvbv369FixZl6b4AAAAAAGCWLAVTqaNGSpUqpbp166aZXvagmTdvnrp3766AgACVK1dOU6ZMUdOmTU2rJyQkRF27dlWFChX077//6sSJE/Lx8VFkZKSGDRumpk2bKikpSd7e3mrWrJl16tu9mDRpkvr3769jx46pWrVq+vrrr2Vvby/p5mifrVu3auTIkXrqqadkGIbKlClz1yfotWrVSgMHDlSfPn2UlJSkZ599VqNHj1ZoaKh1n/bt22vlypVq2LChLl68qPnz56tbt27Z/pm8++67evXVV1W3bl0VLFhQw4YNy/IT5QYPHqyffvpJYWFhcnd317vvvqugoKA7HtOmTRvNnDlT06ZNU//+/VWqVCnNnz9fgYGB1n1WrFihkJAQderUSYmJifL19dWkSZMk3f0e58uXTytXrlRoaKiuXr0qPz8/LVmyRBUrVlRUVJR++OEHzZgxQ5cuXZK3t7emT5+u5s2bS5L69eun+Ph4DR48WGfOnFGFChW0Zs0a+fn5Zem+AAAAAABglmw9le9WV69eTbPOT2ZWXcd/K/XpdhcuXFC+fPnMLsd0Pj4+GjBggAYMGGB2KQ+U1Kcl8FQ+AACAtHgqHwBk3X15Kt+VK1fUp08fFSpUSC4uLvLw8LB5AQAAAAAAAHeTrWBqyJAh+v777zVnzhw5ODjo008/VVhYmLy8vLRw4cKcrvGBERsbK1dX13RfuXLlUq5cuTLcHhsba3b5j6xt27ZleN9dXV3NLg8AAAAAAGQgW4+B+/rrr7Vw4UIFBgbqlVde0VNPPSVfX195e3tr0aJFevHFF3O6zgeCl5dXtp/s5+XllbPF3EVgYKDucZbmQ6NmzZp3/blk9Ql+AAAAAADgv5etYOr8+fMqXbq0pJvrSZ0/f16SVL9+fb3xxhs5V90Dxs7OTr6+vmaXgds4OTnxcwEAAAAA4CGUral8pUuX1okTJyRJ5cuX15dffinp5kgqFtoGAAAAAABAZmQrmHrllVd04MABSdLw4cP14YcfytHRUQMHDtSQIUNytEAAAAAAAAA8mrI1lW/gwIHWf27SpIl+++03/fzzz/L19VWVKlVyrDgAAAAAAAA8urIVTN3q6tWr8vb2lre3d07UAwAAAAAAgMdEtqbyJScna/z48SpWrJhcXV31+++/S5JGjx6t//3vfzlaIAAAAAAAAB5N2Qqm3n77bYWHh2vKlCmyt7e3tleqVEmffvppjhUHAAAAAACAR1e2gqmFCxfqk08+0YsvvqjcuXNb26tWrarffvstx4oDAAAAAADAoytbwdTp06fl6+ubpj0lJUXXr1+/56IAAAAAAADw6MtWMFWhQgVt27YtTfvy5ctVvXr1ey4KAAAAAAAAj75sPZVvzJgx6tq1q06fPq2UlBStXLlSR44c0cKFC/XNN9/kdI0AAAAAAAB4BGVpxNTvv/8uwzDUunVrff311/ruu+/k4uKiMWPGKCoqSl9//bWeeeaZ/6pWAAAAAAAAPEKyNGLKz89PcXFxKlSokJ566inlz59fBw8eVOHChf+r+gAAAAAAAPCIytKIKcMwbN6vW7dOiYmJOVoQAAAAAAAAHg/ZWvw81e1BFQAAAAAAAJBZWQqmLBaLLBZLmjYAAAAAAAAgq7K0xpRhGOrWrZscHBwkSVevXlWvXr3k4uJis9/KlStzrkIAAAAAAAA8krIUTHXt2tXm/UsvvZSjxQAAAAAAAODxkaVgav78+f9VHQAAAAAAAHjM3NPi5wAAAAAAAEB2EUwBAAAAAADAFARTAAAAAAAAMEWW1pgC8GiKHDpC7u7uZpcBAAAAAHjMMGIKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCkIpgAAAAAAAGAKgikAAAAAAACYgmAKAAAAAAAApiCYAgAAAAAAgCnszC4AgPka/G+Ccjs5mF3GffdTr/FmlwAAAAAAjzVGTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFNADgoNDVW1atXMLgMAAAAAgIcCwRQeGzkdGlksFq1evdqmLSQkRJs3b86xc9xNTEyMLBaL9u/ff9/OCQAAAABATrEzuwDgUeLq6ipXV1ezywAAAAAA4KHAiCk8VFJSUjRlyhT5+vrKwcFBJUuW1Ntvvy1JGjZsmMqWLStnZ2eVLl1ao0eP1vXr1yVJ4eHhCgsL04EDB2SxWGSxWBQeHp7tOnx8fCRJbdu2lcVisb6/fVRWt27d1KZNG4WFhcnT01Pu7u7q1auXrl27Zt0nKSlJ/fr1U6FCheTo6Kj69etrz5492a4NAAAAAICHBSOm8FAZMWKE5s6dq/fee0/169dXXFycfvvtN0mSm5ubwsPD5eXlpYMHD6pHjx5yc3PT0KFD9fzzz+vQoUNav369vvvuO0lS3rx5s13Hnj17VKhQIc2fP1/NmjVT7ty5M9x38+bNcnR0VEREhGJiYvTKK6+oQIEC1kBt6NChWrFihRYsWCBvb29NmTJFQUFBOn78uPLnz5/tGtOTlJSkpKQk6/tLly7laP8AAAAAAGQFI6bw0Lh8+bJmzpypKVOmqGvXripTpozq16+v1157TZI0atQo1a1bVz4+PmrZsqVCQkL05ZdfSpKcnJzk6uoqOzs7FSlSREWKFJGTk1O2a/H09JQk5cuXT0WKFLG+T4+9vb3mzZunihUr6tlnn9W4ceP0/vvvKyUlRYmJiZozZ46mTp2q5s2bq0KFCpo7d66cnJz0v//9L9v1ZWTixInKmzev9VWiRIkcPwcAAAAAAJnFiCk8NKKiopSUlKTGjRunu/2LL77Q+++/r+joaCUkJOjGjRtyd3e/z1WmVbVqVTk7O1vfP/nkk0pISNCpU6cUHx+v69evq169etbtefLkUe3atRUVFZXjtYwYMUKDBg2yvr906RLhFAAAAADANIyYwkPjTiOcdu7cqRdffFEtWrTQN998o3379mnkyJE2azlBcnBwkLu7u80LAAAAAACzEEzhoeHn5ycnJydt3rw5zbYdO3bI29tbI0eOVM2aNeXn56eTJ0/a7GNvb6/k5OQcqydPnjyZ6u/AgQP6999/re9//PFHubq6qkSJEipTpozs7e0VGRlp3X79+nXt2bNHFSpUyLFaAQAAAAB4EDGVDw8NR0dHDRs2TEOHDpW9vb3q1auns2fP6tdff5Wfn59iY2O1dOlS1apVS2vXrtWqVatsjvfx8dGJEye0f/9+FS9eXG5ubnJwcMh2PT4+Ptq8ebPq1asnBwcHeXh4pLvftWvX1L17d40aNUoxMTEaO3as+vTpo1y5csnFxUVvvPGGhgwZovz586tkyZKaMmWKrly5ou7du2e6liNHjqRpq1ixovLkyZPt6wMAAAAA4L9GMIWHyujRo2VnZ6cxY8bozz//VNGiRdWrVy91795dAwcOVJ8+fZSUlKRnn31Wo0ePVmhoqPXY9u3ba+XKlWrYsKEuXryo+fPnq1u3btmuZfr06Ro0aJDmzp2rYsWKKSYmJt39GjduLD8/Pz399NNKSkpSp06dbOqaNGmSUlJS1KVLF12+fFk1a9bUhg0bMgy60vPCCy+kaTt16pSKFy+e1csCAAAAAOC+sRiGYZhdBPCo6tatmy5evKjVq1ebXUq6Ll26pLx586rau0OU2yn7o8ceVj/1Gm92CQAAAADwSEn9OzM+Pj5T6xqzxhQAAAAAAABMQTCFx9aiRYvk6uqa7qtUqVIZbqtYseJ9q7FXr14Z1tGrV6/7VgcAAAAAAP8FpvLhsXX58mX9/fff6W7LkyePrl+/nuE2b2/v/7I0qzNnzujSpUvpbnN3d1ehQoXuqX+m8jGVDwAAAAByUlan8rH4OR5bbm5ucnNzM7uMOypUqNA9h08AAAAAADyomMoHAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAUxBMAQAAAAAAwBQEUwAAAAAAADAFwRQAAAAAAABMQTAFAAAAAAAAU9iZXQAA823tPkru7u5mlwEAAAAAeMwwYgoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKQimAAAAAAAAYAqCKQAAAAAAAJiCYAoAAAAAAACmIJgCAAAAAACAKezMLgCA+bqsHa08zg5ml5Epy1tPMbsEAAAAAEAOYcQUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBQAAAAAAAFMQTAEAAAAAAMAUBFMAAAAAAAAwBcEUAAAAAAAATEEwBdyD0NBQVatWzewyAAAAAAB4KBFM4ZGV06GRxWLR6tWrbdpCQkK0efPmHDvH3cTExMhisSh37tw6ffq0zba4uDjZ2dnJYrEoJibmvtUEAAAAAEB2EUwB98DV1VUFChS47+ctVqyYFi5caNO2YMECFStW7L7XAgAAAABAdhFM4YGWkpKiKVOmyNfXVw4ODipZsqTefvttSdKwYcNUtmxZOTs7q3Tp0ho9erSuX78uSQoPD1dYWJgOHDggi8Uii8Wi8PDwbNfh4+MjSWrbtq0sFov1/e2jsrp166Y2bdooLCxMnp6ecnd3V69evXTt2jXrPklJSerXr58KFSokR0dH1a9fX3v27MlSPV27dtX8+fNt2ubPn6+uXbtm6/oAAAAAADADwRQeaCNGjNCkSZM0evRoHT58WIsXL1bhwoUlSW5ubgoPD9fhw4c1c+ZMzZ07V++9954k6fnnn9fgwYNVsWJFxcXFKS4uTs8//3y260gNjubPn6+4uLg7BkmbN29WVFSUIiIitGTJEq1cuVJhYWHW7UOHDtWKFSu0YMEC7d27V76+vgoKCtL58+czXU+rVq104cIFbd++XZK0fft2XbhwQS1btszmFQIAAAAAcP8RTOGBdfnyZc2cOVNTpkxR165dVaZMGdWvX1+vvfaaJGnUqFGqW7eufHx81LJlS4WEhOjLL7+UJDk5OcnV1VV2dnYqUqSIihQpIicnp2zX4unpKUnKly+fihQpYn2fHnt7e82bN08VK1bUs88+q3Hjxun9999XSkqKEhMTNWfOHE2dOlXNmzdXhQoVNHfuXDk5Oel///tfpuvJkyePXnrpJc2bN0+SNG/ePL300kvKkyfPHY9LSkrSpUuXbF4AAAAAAJjFzuwCgIxERUUpKSlJjRs3Tnf7F198offff1/R0dFKSEjQjRs35O7ufp+rTKtq1apydna2vn/yySeVkJCgU6dOKT4+XtevX1e9evWs2/PkyaPatWsrKioqS+d59dVXVbduXb3zzjtatmyZdu7cqRs3btzxmIkTJ9qM3gIAAAAAwEyMmMID604jnHbu3KkXX3xRLVq00DfffKN9+/Zp5MiRNms5PeoqV66s8uXLq1OnTvL391elSpXuesyIESMUHx9vfZ06deo+VAoAAAAAQPoIpvDA8vPzk5OTkzZv3pxm244dO+Tt7a2RI0eqZs2a8vPz08mTJ232sbe3V3Jyco7VkydPnkz1d+DAAf3777/W9z/++KNcXV1VokQJlSlTRvb29oqMjLRuv379uvbs2aMKFSpkuaZXX31VERERevXVVzO1v4ODg9zd3W1eAAAAAACYhal8eGA5Ojpq2LBhGjp0qOzt7VWvXj2dPXtWv/76q/z8/BQbG6ulS5eqVq1aWrt2rVatWmVzvI+Pj06cOKH9+/erePHicnNzk4ODQ7br8fHx0ebNm1WvXj05ODjIw8Mj3f2uXbum7t27a9SoUYqJidHYsWPVp08f5cqVSy4uLnrjjTc0ZMgQ5c+fXyVLltSUKVN05coVde/ePcs19ejRQx07dlS+fPmyfV0AAAAAAJiFEVN4oI0ePVqDBw/WmDFj5O/vr+eff15nzpxRq1atNHDgQPXp00fVqlXTjh07NHr0aJtj27dvr2bNmqlhw4by9PTUkiVL7qmW6dOna9OmTSpRooSqV6+e4X6NGzeWn5+fnn76aT3//PNq1aqVQkNDrdsnTZqk9u3bq0uXLqpRo4aOHz+uDRs2ZBh03YmdnZ0KFiwoOzsyZgAAAADAw8diGIZhdhHAo6Jbt266ePGiVq9ebXYpmXLp0iXlzZtXrRb3Ux7n7I8mu5+Wt55idgkAAAAAgAyk/p0ZHx+fqeVjGDEFAAAAAAAAUxBM4bGxaNEiubq6pvsqVapUhtsqVqx432rs1atXhnX06tXrvtUBAAAAAMD9wFQ+PDYuX76sv//+O91tefLk0fXr1zPc5u39/9q79+ioynv/458JITeSSSBXUnIBiSUQAoEoxqAgoJFbBa1QyKEBqR4QCggI0oLcbEmxnCOoRaVgOBSMeiwcb4AxCBXkkgSiXGIECobjCUSB3ABJSPbvDxbz68hFLjFPYN6vtWatzH6eefZ3zzxrM3zWs/dE/ZSlOZSUlKi8vPySbXa7XSEhIXW6Py7lAwAAAADUpWu9lI87JsNl+Pn5yc/Pz3QZVxQSElLn4RMAAAAAAA0Vl/IBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjHA3XQAA81b0nSu73W66DAAAAACAi2HFFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjCCYAgAAAAAAgBEEUwAAAAAAADCCYAoAAAAAAABGEEwBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACPcTRcAwLx5W56UVxOPOhtv5r3L6mwsAAAAAMCtixVTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjCCYAgAAAAAAgBEEUwAAAAAAADCCYAoAAAAAAABGEEwBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMIJgCrhBs2bNUseOHU2XAQAAAADATYdgCre0ug6NbDab1qxZ47Rt8uTJys7OrrN9/JjDhw/LZrMpPz//orbu3btrwoQJ9VYLAAAAAAA3wt10AcDNztfXV76+vqbLAAAAAADgpsOKKTR4tbW1mj9/vlq3bi1PT09FRkbqD3/4gyRp6tSpuv322+Xj46NWrVppxowZqq6uliRlZGRo9uzZ+vzzz2Wz2WSz2ZSRkXHddURHR0uSBg4cKJvN5nj+w1VZw4cP14ABAzR79mwFBwfLbrdr1KhRqqqqcvQ5e/asxo0bp5CQEHl5ealr167Kycm57toAAAAAALgZsWIKDd60adO0ZMkS/ed//qe6du2q4uJiffnll5IkPz8/ZWRkKDw8XLt379bjjz8uPz8/TZkyRYMHD9aePXu0bt06ffzxx5Ikf3//664jJydHISEhev311/Xggw+qUaNGl+2bnZ0tLy8vbdy4UYcPH9aIESMUGBjoCNSmTJmid955R8uXL1dUVJTmz5+vlJQUHThwQM2aNbvuGn/M2bNndfbsWcfz8vLyn2xfAAAAAAD8GFZMoUGrqKjQwoULNX/+fKWlpem2225T165d9Zvf/EaSNH36dN19992Kjo5W//79NXnyZL311luSJG9vb/n6+srd3V1hYWEKCwuTt7f3ddcSHBwsSQoICFBYWJjj+aV4eHho2bJlateunfr27as5c+Zo0aJFqq2t1alTp7R48WI9//zz6t27t9q2baslS5bI29tbS5cuvep67r77bsdlhBcen3766RVfM2/ePPn7+zseERERV70/AAAAAADqGium0KAVFBTo7Nmz6tmz5yXb33zzTS1atEgHDx5UZWWlzp07J7vdXs9VXqxDhw7y8fFxPE9KSlJlZaWOHDmisrIyVVdXKzk52dHeuHFj3XnnnSooKLjqfbz55puKjY112paamnrF10ybNk0TJ050PC8vLyecAgAAAAAYQzCFBu1KK5y2bt2q1NRUzZ49WykpKfL391dmZqYWLFhQjxWaExERodatWztt+7EVYZ6envL09PwpywIAAAAA4KpxKR8atJiYGHl7eys7O/uits8++0xRUVH6/e9/r8TERMXExOjrr7926uPh4aGampo6q6dx48ZXNd7nn3+uM2fOOJ5v27ZNvr6+ioiI0G233SYPDw9t2bLF0V5dXa2cnBy1bdu2zmoFAAAAAKChY8UUGjQvLy9NnTpVU6ZMkYeHh5KTk/Xtt99q7969iomJUVFRkTIzM3XHHXfogw8+0OrVq51eHx0drUOHDik/P18tWrSQn5/fDa0Yio6OVnZ2tpKTk+Xp6ammTZtesl9VVZVGjhyp6dOn6/Dhw5o5c6bGjh0rNzc3NWnSRKNHj9bTTz+tZs2aKTIyUvPnz9fp06c1cuTI664NAAAAAICbDSum0ODNmDFDkyZN0rPPPqvY2FgNHjxYJSUl+sUvfqGnnnpKY8eOVceOHfXZZ59pxowZTq995JFH9OCDD+q+++5TcHCw3njjjRuqZcGCBcrKylJERIQSEhIu269nz56KiYnRvffeq8GDB+sXv/iFZs2a5WhPT0/XI488omHDhqlTp046cOCA1q9ff9mgCwAAAACAW5HNsizLdBHArWT48OEqLS3VmjVrTJfyo8rLy+Xv769nPkyVVxOPOht35r3L6mwsAAAAAMDN48L/M8vKyq7qx8lYMQUAAAAAAAAjCKbgUlauXClfX99LPlq2bHnZtnbt2tVbjaNGjbpsHaNGjaq3OgAAAAAA+KlxKR9cSkVFhY4dO3bJtsaNG6u6uvqybVFRUT9laQ4lJSUqLy+/ZJvdbldISEid7YtL+QAAAAAAdelaL+XjV/ngUvz8/OTn52e6jCsKCQmp0/AJAAAAAICGikv5AAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjCCYAgAAAAAAgBEEUwAAAAAAADCCYAoAAAAAAABGEEwBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMMLddAEAzJuW/BfZ7XbTZQAAAAAAXAwrpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjCCYAgAAAAAAgBEEUwAAAAAAADCCYAoAAAAAAABGEEwBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEU6tysWbPUsWPHK/YZPny4BgwYcEP7OXz4sGw2m/Lz829onBvVvXt3TZgwocGMAwAAAADAzYJgCnVu8uTJys7ONl1Gg7Vx40bZbDaVlpY6bf/73/+uuXPnmikKAAAAAAAD3E0XgFuPr6+vfH19TZdxw6qqquTh4VFv+2vWrFm97QsAAAAAgIaAFVN1qHv37ho3bpymTJmiZs2aKSwsTLNmzZJ06cvOSktLZbPZtHHjRkn/fyXN+vXrlZCQIG9vb/Xo0UMlJSVau3atYmNjZbfbNXToUJ0+ffqG642OjtYLL7zgtK1jx46OmiXJZrPp1VdfVb9+/eTj46PY2Fht3bpVBw4cUPfu3dWkSRPdfffdOnjwoOM1P7yUr6amRhMnTlRAQIACAwM1ZcoUWZbltN9169apa9eujj79+vVzGlOSduzYoYSEBHl5eSkxMVG7du266Jj27Nmj3r17y9fXV6GhoRo2bJi+++67q3o/unfvrrFjx2rChAkKCgpSSkrKdY25YsUKJSYmys/PT2FhYRo6dKhKSkoknZ8H9913nySpadOmstlsGj58uGP/Fy7l+93vfqcuXbpcNHaHDh00Z84cSVJOTo7uv/9+BQUFyd/fX926ddPOnTuv6lgBAAAAAGgICKbq2PLly9WkSRNt375d8+fP15w5c5SVlXVNY8yaNUsvvfSSPvvsMx05ckSDBg3SCy+8oFWrVumDDz7QRx99pBdffPEnOoKLzZ07V7/+9a+Vn5+vNm3aaOjQofr3f/93TZs2Tbm5ubIsS2PHjr3s6xcsWKCMjAwtW7ZMmzdv1okTJ7R69WqnPqdOndLEiROVm5ur7Oxsubm5aeDAgaqtrZUkVVZWql+/fmrbtq3y8vI0a9YsTZ482WmM0tJS9ejRQwkJCcrNzdW6det07NgxDRo06KqPdfny5fLw8NCWLVv0yiuvXNeY1dXVmjt3rj7//HOtWbNGhw8fdoRPEREReueddyRJhYWFKi4u1sKFCy8aIzU1VTt27HAK5/bu3asvvvhCQ4cOlSRVVFQoLS1Nmzdv1rZt2xQTE6M+ffqooqLisrWdPXtW5eXlTg8AAAAAAEzhUr46Fh8fr5kzZ0qSYmJi9NJLLyk7O1sxMTFXPcZzzz2n5ORkSdLIkSM1bdo0HTx4UK1atZIk/fKXv9Qnn3yiqVOn1v0BXMKIESMcQczUqVOVlJSkGTNmOFYUjR8/XiNGjLjs61944QVNmzZNDz/8sCTplVde0fr16536PPLII07Ply1bpuDgYO3bt09xcXFatWqVamtrtXTpUnl5ealdu3b63//9X40ePdrxmpdeekkJCQn64x//6DRORESEvvrqK91+++0/eqwxMTGaP3++4/lzzz13zWM+9thjjr9btWqlRYsW6Y477lBlZaV8fX0dl+yFhIQoICDgknW0a9dOHTp00KpVqzRjxgxJ0sqVK9WlSxe1bt1aktSjRw+n17z22msKCAjQpk2b1K9fv0uOO2/ePM2ePftH3wcAAAAAAOoDK6bqWHx8vNPz5s2bOy7jup4xQkND5ePj4wilLmy71jFvxA/rkaT27ds7bfv+++8vufqmrKxMxcXFTpelubu7KzEx0anf/v37NWTIELVq1Up2u13R0dGSpKKiIklSQUGB4uPj5eXl5XhNUlKS0xiff/65PvnkE8c9rnx9fdWmTRtJuuiywMvp3LnzDY+Zl5en/v37KzIyUn5+furWrZvTsVyt1NRUrVq1SpJkWZbeeOMNpaamOtqPHTumxx9/XDExMfL395fdbldlZeUV9zNt2jSVlZU5HkeOHLmmmgAAAAAAqEusmKpjjRs3dnpus9lUW1srN7fzGeC/3lupurr6R8ew2WyXHfNGubm5XXSvp0vV9MN6LrftRmrq37+/oqKitGTJEoWHh6u2tlZxcXGqqqq66jEqKyvVv39//elPf7qorXnz5lc1RpMmTW5ozFOnTiklJUUpKSlauXKlgoODVVRUpJSUlGs6FkkaMmSIpk6dqp07d+rMmTM6cuSIBg8e7GhPS0vT8ePHtXDhQkVFRcnT01NJSUlX3I+np6c8PT2vqQ4AAAAAAH4qBFP1JDg4WJJUXFyshIQESXK6EboJwcHBKi4udjwvLy/XoUOH6nQf/v7+at68ubZv3657771XknTu3Dnl5eWpU6dOkqTjx4+rsLBQS5Ys0T333CNJ2rx5s9M4sbGxWrFihb7//nvHqqlt27Y59enUqZPeeecdRUdHy929bqb2tY755Zdf6vjx40pPT1dERIQkKTc316nPhV/6q6mpueJYLVq0ULdu3bRy5UqdOXNG999/v0JCQhztW7Zs0V/+8hf16dNHknTkyJGrvtE7AAAAAAANAZfy1RNvb2/dddddSk9PV0FBgTZt2qTp06cbralHjx5asWKFPv30U+3evVtpaWlq1KhRne9n/PjxSk9P15o1a/Tll1/qySefVGlpqaO9adOmCgwM1GuvvaYDBw5ow4YNmjhxotMYQ4cOlc1m0+OPP659+/bpww8/1J///GenPmPGjNGJEyc0ZMgQ5eTk6ODBg1q/fr1GjBjxoyHQ5VzrmJGRkfLw8NCLL76of/7zn3r33Xc1d+5cpz5RUVGy2Wx6//339e2336qysvKy+09NTVVmZqbefvttp8v4pPP3w1qxYoUKCgq0fft2paamytvb+7qOEwAAAAAAEwim6tGyZct07tw5de7cWRMmTNBzzz1ntJ5p06apW7du6tevn/r27asBAwbotttuq/P9TJo0ScOGDVNaWpqSkpLk5+engQMHOtrd3NyUmZmpvLw8xcXF6amnntLzzz/vNIavr6/ee+897d69WwkJCfr9739/0eV14eHh2rJli2pqavTAAw+offv2mjBhggICAhyXUl6rax0zODhYGRkZevvtt9W2bVulp6dfFKD97Gc/0+zZs/XMM88oNDT0ir9o+Mtf/lLHjx/X6dOnNWDAAKe2pUuX6uTJk+rUqZOGDRumcePGOa2oAgAAAACgobNZP7zJEACXUV5eLn9/f5WVlclut5suBwAAAABwk7vW/2eyYgoAAAAAAABGcPPzm1hRUZHatm17ybbTp09Lknx8fC7Zvm/fPkVGRv5ktTU0V3qvJNd7PwAAAAAAaAgIpm5i4eHh1/3LfuHh4XVbTAP3Y++Vq70fAAAAAAA0BARTNzF3d3e1bt3adBk3Bd4rAAAAAAAaHu4xBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMIJgCAAAAAACAEQRTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAQAAAAAAwAiCKQAAAAAAABhBMAUAAAAAAAAjCKYAAAAAAABgBMEUAAAAAAAAjCCYAgAAAAAAgBEEUwAAAAAAADCCYAoAAAAAAABGEEwBAAAAAADACIIpAAAAAAAAGEEwBQAAAAAAACMIpgAAAAAAAGAEwRQAAAAAAACMcDddAABzLMuSJJWXlxuuBAAAAABwK7jw/8sL/9/8MQRTgAs7fvy4JCkiIsJwJQAAAACAW0lFRYX8/f1/tB/BFODCmjVrJkkqKiq6qhMGbk3l5eWKiIjQkSNHZLfbTZcDQ5gHkJgHOI95AIl5gPOYB5CufR5YlqWKigqFh4df1fgEU4ALc3M7f5s5f39//qGB7HY78wDMA0hiHuA85gEk5gHOYx5AurZ5cC0LH7j5OQAAAAAAAIwgmAIAAAAAAIARBFOAC/P09NTMmTPl6elpuhQYxDyAxDzAecwDSMwDnMc8gMQ8wHk/9TywWVf7+30AAAAAAABAHWLFFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAwgmAKAAAAAAAARhBMAS7s5ZdfVnR0tLy8vNSlSxft2LHDdEmoQ//4xz/Uv39/hYeHy2azac2aNU7tlmXp2WefVfPmzeXt7a1evXpp//79Tn1OnDih1NRU2e12BQQEaOTIkaqsrKzHo8CNmDdvnu644w75+fkpJCREAwYMUGFhoVOf77//XmPGjFFgYKB8fX31yCOP6NixY059ioqK1LdvX/n4+CgkJERPP/20zp07V5+HghuwePFixcfHy263y263KykpSWvXrnW0MwdcU3p6umw2myZMmODYxly49c2aNUs2m83p0aZNG0c7c8B1fPPNN/q3f/s3BQYGytvbW+3bt1dubq6jne+Jt77o6OiLzgc2m01jxoyRVL/nA4IpwEW9+eabmjhxombOnKmdO3eqQ4cOSklJUUlJienSUEdOnTqlDh066OWXX75k+/z587Vo0SK98sor2r59u5o0aaKUlBR9//33jj6pqanau3evsrKy9P777+sf//iHnnjiifo6BNygTZs2acyYMdq2bZuysrJUXV2tBx54QKdOnXL0eeqpp/Tee+/p7bff1qZNm/R///d/evjhhx3tNTU16tu3r6qqqvTZZ59p+fLlysjI0LPPPmvikHAdWrRoofT0dOXl5Sk3N1c9evTQQw89pL1790piDriinJwcvfrqq4qPj3fazlxwDe3atVNxcbHjsXnzZkcbc8A1nDx5UsnJyWrcuLHWrl2rffv2acGCBWratKmjD98Tb305OTlO54KsrCxJ0qOPPiqpns8HFgCXdOedd1pjxoxxPK+pqbHCw8OtefPmGawKPxVJ1urVqx3Pa2trrbCwMOv55593bCstLbU8PT2tN954w7Isy9q3b58lycrJyXH0Wbt2rWWz2axvvvmm3mpH3SkpKbEkWZs2bbIs6/xn3rhxY+vtt9929CkoKLAkWVu3brUsy7I+/PBDy83NzTp69Kijz+LFiy273W6dPXu2fg8AdaZp06bWX//6V+aAC6qoqLBiYmKsrKwsq1u3btb48eMty+J84CpmzpxpdejQ4ZJtzAHXMXXqVKtr166Xbed7omsaP368ddttt1m1tbX1fj5gxRTggqqqqpSXl6devXo5trm5ualXr17aunWrwcpQXw4dOqSjR486zQF/f3916dLFMQe2bt2qgIAAJSYmOvr06tVLbm5u2r59e73XjBtXVlYmSWrWrJkkKS8vT9XV1U7zoE2bNoqMjHSaB+3bt1doaKijT0pKisrLyx0rbnDzqKmpUWZmpk6dOqWkpCTmgAsaM2aM+vbt6/SZS5wPXMn+/fsVHh6uVq1aKTU1VUVFRZKYA67k3XffVWJioh599FGFhIQoISFBS5YscbTzPdH1VFVV6W9/+5see+wx2Wy2ej8fEEwBLui7775TTU2N00lEkkJDQ3X06FFDVaE+XficrzQHjh49qpCQEKd2d3d3NWvWjHlyE6qtrdWECROUnJysuLg4Sec/Yw8PDwUEBDj1/eE8uNQ8udCGm8Pu3bvl6+srT09PjRo1SqtXr1bbtm2ZAy4mMzNTO3fu1Lx58y5qYy64hi5duigjI0Pr1q3T4sWLdejQId1zzz2qqKhgDriQf/7zn1q8eLFiYmK0fv16jR49WuPGjdPy5csl8T3RFa1Zs0alpaUaPny4pPr/N8H9+soGAAA3kzFjxmjPnj1O9xKB6/j5z3+u/Px8lZWV6b//+7+VlpamTZs2mS4L9ejIkSMaP368srKy5OXlZbocGNK7d2/H3/Hx8erSpYuioqL01ltvydvb22BlqE+1tbVKTEzUH//4R0lSQkKC9uzZo1deeUVpaWmGq4MJS5cuVe/evRUeHm5k/6yYAlxQUFCQGjVqdNGvKhw7dkxhYWGGqkJ9uvA5X2kOhIWFXXQz/HPnzunEiRPMk5vM2LFj9f777+uTTz5RixYtHNvDwsJUVVWl0tJSp/4/nAeXmicX2nBz8PDwUOvWrdW5c2fNmzdPHTp00MKFC5kDLiQvL08lJSXq1KmT3N3d5e7urk2bNmnRokVyd3dXaGgoc8EFBQQE6Pbbb9eBAwc4H7iQ5s2bq23btk7bYmNjHZd18j3RtXz99df6+OOP9Zvf/Maxrb7PBwRTgAvy8PBQ586dlZ2d7dhWW1ur7OxsJSUlGawM9aVly5YKCwtzmgPl5eXavn27Yw4kJSWptLRUeXl5jj4bNmxQbW2tunTpUu8149pZlqWxY8dq9erV2rBhg1q2bOnU3rlzZzVu3NhpHhQWFqqoqMhpHuzevdvpy2dWVpbsdvtFX2px86itrdXZs2eZAy6kZ8+e2r17t/Lz8x2PxMREpaamOv5mLrieyspKHTx4UM2bN+d84EKSk5NVWFjotO2rr75SVFSUJL4nuprXX39dISEh6tu3r2NbvZ8P6uT27QBuOpmZmZanp6eVkZFh7du3z3riiSesgIAAp19VwM2toqLC2rVrl7Vr1y5LkvUf//Ef1q5du6yvv/7asizLSk9PtwICAqz/+Z//sb744gvroYceslq2bGmdOXPGMcaDDz5oJSQkWNu3b7c2b95sxcTEWEOGDDF1SLhGo0ePtvz9/a2NGzdaxcXFjsfp06cdfUaNGmVFRkZaGzZssHJzc62kpCQrKSnJ0X7u3DkrLi7OeuCBB6z8/Hxr3bp1VnBwsDVt2jQTh4Tr8Mwzz1ibNm2yDh06ZH3xxRfWM888Y9lsNuujjz6yLIs54Mr+9Vf5LIu54AomTZpkbdy40Tp06JC1ZcsWq1evXlZQUJBVUlJiWRZzwFXs2LHDcnd3t/7whz9Y+/fvt1auXGn5+PhYf/vb3xx9+J7oGmpqaqzIyEhr6tSpF7XV5/mAYApwYS+++KIVGRlpeXh4WHfeeae1bds20yWhDn3yySeWpIseaWlplmWd/yngGTNmWKGhoZanp6fVs2dPq7Cw0GmM48ePW0OGDLF8fX0tu91ujRgxwqqoqDBwNLgel/r8JVmvv/66o8+ZM2esJ5980mratKnl4+NjDRw40CouLnYa5/Dhw1bv3r0tb29vKygoyJo0aZJVXV1dz0eD6/XYY49ZUVFRloeHhxUcHGz17NnTEUpZFnPAlf0wmGIu3PoGDx5sNW/e3PLw8LB+9rOfWYMHD7YOHDjgaGcOuI733nvPiouLszw9Pa02bdpYr732mlM73xNdw/r16y1JF322llW/5wObZVnWNa/1AgAAAAAAAG4Q95gCAAAAAACAEQRTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAHCDtm7dqkWLFpkuAwCAm4676QIAAACAm1lFRYVGjhypoKAgBQUFaejQoXU6/vDhw1VaWqo1a9bU6bgAADQENsuyLNNFAAAAAA05gDl8+LBatmypXbt2qWPHjk5tY8aMUWJiovr3769evXopKytLwcHBdbbvsrIyWZalgICAOhsTAICGghVTAAAAwBVUVVVdsf3ll192/J2fn1/n+/f396/zMQEAaCi4xxQAAAAanO7du+u3v/2tJkyYoKZNmyo0NFRLlizRqVOnNGLECPn5+al169Zau3at4zUbN26UzWbTBx98oPj4eHl5eemuu+7Snj17nMZ+55131K5dO3l6eio6OloLFixwao+OjtbcuXP161//Wna7XU888YRatmwpSUpISJDNZlP37t0lSTk5Obr//vsVFBQkf39/devWTTt37nQaz2az6a9//asGDhwoHx8fxcTE6N1333Xqs3fvXvXr1092u11+fn665557dPDgQUnnV5INGDDA0XfdunXq2rWrAgICFBgYqH79+jn6AgBwsyGYAgAAQIO0fPlyBQUFaceOHfrtb3+r0aNH69FHH9Xdd9+tnTt36oEHHtCwYcN0+vRpp9c9/fTTWrBggXJychQcHKz+/fururpakpSXl6dBgwbpV7/6lXbv3q1Zs2ZpxowZysjIcBrjz3/+szp06KBdu3ZpxowZ2rFjhyTp448/VnFxsf7+979LOn9/qbS0NG3evFnbtm1TTEyM+vTpo4qKCqfxZs+erUGDBumLL75Qnz59lJqaqhMnTkiSvvnmG917773y9PTUhg0blJeXp8cee0znzp275Pty6tQpTZw4Ubm5ucrOzpabm5sGDhyo2traG37PAQCob9xjCgAAAA3Cv95jqnv37qqpqdGnn34qSaqpqZG/v78efvhh/dd//Zck6ejRo2revLm2bt2qu+66Sxs3btR9992nzMxMDR48WJJ04sQJtWjRQhkZGRo0aJBSU1P17bff6qOPPnLsd8qUKfrggw+0d+9eSedXTCUkJGj16tWOPle6x9S/qq2tVUBAgFatWqV+/fpJOr9iavr06Zo7d66k88GSr6+v1q5dqwcffFC/+93vlJmZqcLCQjVu3PiK78ulfPfddwoODtbu3bsVFxd3le82AAANAyumAAAA0CDFx8c7/m7UqJECAwPVvn17x7bQ0FBJUklJidPrkpKSHH83a9ZMP//5z1VQUCBJKigoUHJyslP/5ORk7d+/XzU1NY5tiYmJV1XjsWPH9PjjjysmJkb+/v6y2+2qrKxUUVHRZY+lSZMmstvtjrrz8/N1zz33XDKUupT9+/dryJAhatWqlex2u6KjoyXpon0CAHAz4ObnAAAAaJB+GNTYbDanbTabTZJ+kkvYmjRpclX90tLSdPz4cS1cuFBRUVHy9PRUUlLSRTdMv9SxXKjb29v7mmrr37+/oqKitGTJEoWHh6u2tlZxcXE/epN2AAAaIlZMAQAA4Jaybds2x98nT57UV199pdjYWElSbGystmzZ4tR/y5Ytuv3229WoUaPLjunh4SFJTquqLrx23Lhx6tOnj+OG6t9999011RsfH69PP/3UcR+sKzl+/LgKCws1ffp09ezZU7GxsTp58uQ17Q8AgIaEYAoAAAC3lDlz5ig7O1t79uzR8OHDFRQU5PhVu0mTJik7O1tz587VV199peXLl+ull17S5MmTrzhmSEiIvL29tW7dOh07dkxlZWWSpJiYGK1YsUIFBQXavn27UlNTr3kF1NixY1VeXq5f/epXys3N1f79+7VixQoVFhZe1Ldp06YKDAzUa6+9pgMHDmjDhg2aOHHiNe0PAICGhGAKAAAAt5T09HSNHz9enTt31tGjR/Xee+85Vjx16tRJb731ljIzMxUXF6dnn31Wc+bM0fDhw684pru7uxYtWqRXX31V4eHheuihhyRJS5cu1cmTJ9WpUycNGzZM48aNU0hIyDXVGxgYqA0bNqiyslLdunVT586dtWTJkkvec8rNzU2ZmZnKy8tTXFycnnrqKT3//PPXtD8AABoSfpUPAAAAt4QLv8p38uRJBQQEmC4HAABcBVZMAQAAAAAAwAiCKQAAAAAAABjBpXwAAAAAAAAwghVTAAAAAAAAMIJgCgAAAAAAAEYQTAEAAAAAAMAIgikAAAAAAAAYQTAFAAAAAAAAIwimAAAAAAAAYATBFAAAAAAAAIwgmAIAAAAAAIARBFMAAAAAAAAw4v8BI1jNfRc3PuIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarquia de Importância Revelada**\n",
        "\n",
        "O modelo LightGBM identifica três variáveis mecânicas críticas como os principais preditores de falha: **torque (675.4)**, **desgaste da ferramenta (658.4)** e **velocidade rotacional (608.2)**. Esta tríade representa 63% da importância total, confirmando que parâmetros operacionais diretos são mais preditivos que variáveis ambientais.\n",
        "\n",
        "**Fatores Térmicos Secundários**\n",
        "\n",
        "As temperaturas (ar: 509.8, processo: 450.4) ocupam posição intermediária mas significativa, explicando a boa performance do modelo na detecção de falhas térmicas (F1=0.47). A diferença de importância entre temperatura do ar e processo sugere que condições ambientais são mais críticas que temperatura interna para predição de falhas.\n",
        "\n",
        "**Variáveis Categóricas e Irrelevantes**\n",
        "\n",
        "O tipo de produto  tem impacto limitado mas mensurável, indicando que diferentes produtos apresentam perfis de falha ligeiramente distintos. Notavelmente, a umidade relativa tem importância zero, confirmando sua irrelevância para manutenção preditiva neste sistema."
      ],
      "metadata": {
        "id": "6AN3CAGrAT7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 7. AVALIAÇÃO FINAL NO CONJUNTO DE TESTE\n",
        "# ------------------------------------------------------------------------------\n",
        "# Justificativa: Esta é a etapa final e mais importante. Avaliamos o modelo\n",
        "# campeão no conjunto de teste, que foi mantido \"cego\" durante todo o processo.\n",
        "# O resultado aqui é a estimativa mais realista do desempenho do modelo em\n",
        "# dados do mundo real.\n",
        "\n",
        "print(f\"\\n\\n--- Avaliação Final do Modelo '{best_model_name}' no Conjunto de Teste ---\")\n",
        "\n",
        "# Ensure y_test is cleaned of NaNs before evaluation\n",
        "y_test_cleaned_for_eval = y_test.copy()\n",
        "\n",
        "for col in y_test_cleaned_for_eval.columns:\n",
        "    if y_test_cleaned_for_eval[col].isnull().any():\n",
        "         # Calculate mode from the cleaned training data to prevent leakage\n",
        "         # Assuming y_train_limpo is available and represents the cleaned training targets\n",
        "         if 'y_train_limpo' in globals() and not y_train_limpo[col].mode().empty:\n",
        "             mode_value_train = y_train_limpo[col].mode()[0]\n",
        "         elif not y_train[col].mode().empty:\n",
        "              # Fallback to using mode from the original y_train if y_train_limpo is not found\n",
        "              mode_value_train = y_train[col].mode()[0]\n",
        "         else:\n",
        "              # Default to 0 if mode is empty (unlikely for binary)\n",
        "              mode_value_train = 0\n",
        "\n",
        "         y_test_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
        "         print(f\"  NaNs in y_test['{col}'] imputed with mode from y_train ({mode_value_train}).\")\n",
        "    else:\n",
        "        print(f\"  No NaNs found in y_test['{col}'].\")\n",
        "\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_test_pred = best_pipeline.predict(X_test)\n",
        "\n",
        "# Cálculo das métricas finais\n",
        "# Use the cleaned y_test_cleaned_for_eval for calculating metrics\n",
        "final_h_loss = hamming_loss(y_test_cleaned_for_eval, y_test_pred)\n",
        "final_j_score = jaccard_score(y_test_cleaned_for_eval, y_test_pred, average='samples')\n",
        "final_f1_w = f1_score(y_test_cleaned_for_eval, y_test_pred, average='weighted')\n",
        "final_report = classification_report(y_test_cleaned_for_eval, y_test_pred, target_names=target_cols, zero_division=0)\n",
        "\n",
        "print(f\"Resultados Finais:\")\n",
        "print(f\"  Hamming Loss: {final_h_loss:.4f}\")\n",
        "print(f\"  Jaccard Score (samples): {final_j_score:.4f}\")\n",
        "print(f\"  Weighted F1-Score: {final_f1_w:.4f}\")\n",
        "print(\"\\n--- Relatório de Classificação Final ---\")\n",
        "print(final_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja7jf_Qal7Lc",
        "outputId": "637f39fe-c544-441e-b5e1-ac011602a297"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Avaliação Final do Modelo 'LightGBM' no Conjunto de Teste ---\n",
            "  No NaNs found in y_test['fdf_falha_desgaste_ferramenta'].\n",
            "  No NaNs found in y_test['fdc_falha_dissipacao_calor'].\n",
            "  NaNs in y_test['fp_falha_potencia'] imputed with mode from y_train (0.0).\n",
            "  No NaNs found in y_test['fte_falha_tensao_excessiva'].\n",
            "  No NaNs found in y_test['fa_falha_aleatoria'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3800209224.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  y_test_cleaned_for_eval[col].fillna(mode_value_train, inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados Finais:\n",
            "  Hamming Loss: 0.0046\n",
            "  Jaccard Score (samples): 0.0059\n",
            "  Weighted F1-Score: 0.3499\n",
            "\n",
            "--- Relatório de Classificação Final ---\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "fdf_falha_desgaste_ferramenta       0.06      0.08      0.06        13\n",
            "   fdc_falha_dissipacao_calor       0.53      0.42      0.47        43\n",
            "            fp_falha_potencia       0.29      0.33      0.31        18\n",
            "   fte_falha_tensao_excessiva       0.51      0.51      0.51        37\n",
            "           fa_falha_aleatoria       0.00      0.00      0.00        19\n",
            "\n",
            "                    micro avg       0.37      0.34      0.35       130\n",
            "                    macro avg       0.28      0.27      0.27       130\n",
            "                 weighted avg       0.37      0.34      0.35       130\n",
            "                  samples avg       0.01      0.01      0.01       130\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo *LightGBM* demonstra performance consistente no conjunto de teste com Weighted F1-Score de 0.35, ligeiramente inferior ao desempenho de validação (0.46), indicando leve overfitting mas ainda dentro de parâmetros aceitáveis para produção industrial.\n",
        "\n",
        "**Detecção Eficaz por Tipo de Falha**\n",
        "Sucessos do Modelo:\n",
        "\n",
        "- Tensão Excessiva: Excelente performance (F1=0.51, precision/recall equilibrados em 51%)\n",
        "- Dissipação de Calor: Boa detecção (F1=0.47, precision=0.53) para a falha mais crítica\n",
        "- Falha de Potência: Performance moderada (F1=0.31) mas detectável\n",
        "\n",
        "**Limitações Identificadas:**\n",
        "\n",
        "Desgaste de Ferramenta: Detecção mínima (F1=0.06) devido ao extremo desbalanceamento\n",
        "Falhas Aleatórias: Zero detecção (19 amostras insuficientes para aprendizado)\n",
        "Métricas Operacionais\n",
        "O baixo Hamming Loss (0.0046) confirma alta precisão geral, enquanto o Jaccard Score (0.0059) reflete a natureza esparsa das falhas simultâneas. O micro F1-Score (0.35) demonstra capacidade adequada para manutenção preditiva, especialmente considerando o desbalanceamento severo."
      ],
      "metadata": {
        "id": "zHozAbeQ_VbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otimização do modelo\n",
        "\n",
        "Embora LightGBM seja superior (F1=0.46), a diferença não é definitiva e otimização de hiperparâmetros pode reduzir significativamente este gap. XGBoost otimizado pode alcançar performance similar ou até superior, especialmente considerando sua robustez conhecida em datasets desbalanceados e melhor interpretabilidade."
      ],
      "metadata": {
        "id": "Xar00ozQ9czf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SESSÃO 03: OTIMIZAÇÃO DE HIPERPARÂMETROS\n",
        "# Foco: LightGBM e XGBoost\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 0. Importações Adicionais ---\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from scipy.stats import randint, uniform\n"
      ],
      "metadata": {
        "id": "XPe9Xw6X9pti"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Definição da Métrica de Otimização ---\n",
        "# Justificativa: Precisamos dizer ao RandomizedSearchCV qual métrica ele deve\n",
        "# tentar maximizar. O F1-Score Ponderado é uma excelente escolha para nosso\n",
        "# problema multi-label desbalanceado. Usamos `make_scorer` para torná-lo\n",
        "# compatível com o processo de busca.\n",
        "weighted_f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. OTIMIZAÇÃO DO LIGHTGBM\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Iniciando a Otimização para o LightGBM ---\")\n",
        "\n",
        "# --- 2.1. Criação do Pipeline Base ---\n",
        "# Usamos o mesmo pipeline da baseline, apenas com o classificador base.\n",
        "pipeline_lgbm = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(lgb.LGBMClassifier(random_state=42, class_weight='balanced')))\n",
        "])\n",
        "\n",
        "# --- 2.2. Definição do Espaço de Busca de Hiperparâmetros ---\n",
        "# Justificativa: Definimos uma gama de valores para os principais hiperparâmetros.\n",
        "# Usamos distribuições (ex: randint, uniform) para que a busca seja aleatória.\n",
        "# A sintaxe 'classifier__estimator__<param>' é necessária para que o Scikit-learn\n",
        "# saiba que estamos ajustando os parâmetros do LGBMClassifier dentro do MultiOutputClassifier.\n",
        "param_dist_lgbm = {\n",
        "    'classifier__estimator__n_estimators': randint(100, 1000),\n",
        "    'classifier__estimator__learning_rate': uniform(0.01, 0.3),\n",
        "    'classifier__estimator__num_leaves': randint(20, 60),\n",
        "    'classifier__estimator__max_depth': [-1, 10, 20, 30],\n",
        "    'classifier__estimator__reg_alpha': uniform(0, 1), # L1 regularization\n",
        "    'classifier__estimator__reg_lambda': uniform(0, 1), # L2 regularization\n",
        "}\n",
        "\n",
        "# --- 2.3. Configuração e Execução do RandomizedSearchCV ---\n",
        "# n_iter: Número de combinações a serem testadas. 50 é um bom balanço entre tempo e performance.\n",
        "# cv: Número de folds para a validação cruzada.\n",
        "# n_jobs=-1: Utiliza todos os cores de CPU disponíveis para acelerar o processo.\n",
        "random_search_lgbm = RandomizedSearchCV(\n",
        "    pipeline_lgbm,\n",
        "    param_distributions=param_dist_lgbm,\n",
        "    n_iter=50,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42), # KFold simples é robusto aqui\n",
        "    scoring=weighted_f1_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1 # Mostra o progresso do treinamento\n",
        ")\n",
        "\n",
        "# Executando a busca (pode levar alguns minutos)\n",
        "random_search_lgbm.fit(X_train, y_train_limpo)\n",
        "\n",
        "# --- 2.4. Análise dos Resultados da Otimização (LightGBM) ---\n",
        "print(\"\\n--- Resultados da Otimização do LightGBM ---\")\n",
        "print(f\"Melhor F1-Score Ponderado (em CV): {random_search_lgbm.best_score_:.4f}\")\n",
        "print(\"Melhores Hiperparâmetros Encontrados:\")\n",
        "print(random_search_lgbm.best_params_)\n",
        "\n",
        "# Avaliando o melhor modelo encontrado no conjunto de VALIDAÇÃO\n",
        "best_lgbm_model = random_search_lgbm.best_estimator_\n",
        "y_val_pred_lgbm = best_lgbm_model.predict(X_val)\n",
        "f1_val_lgbm = f1_score(y_val_cleaned_for_eval, y_val_pred_lgbm, average='weighted')\n",
        "print(f\"\\nF1-Score Ponderado do Modelo Otimizado (na Validação): {f1_val_lgbm:.4f}\")\n",
        "print(\"\\nRelatório de Classificação Detalhado (Validação - LGBM Otimizado):\")\n",
        "print(classification_report(y_val_cleaned_for_eval, y_val_pred_lgbm, target_names=target_cols, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Tp5slZ9iKy",
        "outputId": "87541b27-dd6b-4022-c86c-8d2a653ad774"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando a Otimização para o LightGBM ---\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[LightGBM] [Info] Number of positive: 44, number of negative: 21112\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 21017\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Info] Number of positive: 79, number of negative: 21077\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Info] Number of positive: 101, number of negative: 21055\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Info] Number of positive: 42, number of negative: 21114\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 21156, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "\n",
            "--- Resultados da Otimização do LightGBM ---\n",
            "Melhor F1-Score Ponderado (em CV): 0.3961\n",
            "Melhores Hiperparâmetros Encontrados:\n",
            "{'classifier__estimator__learning_rate': np.float64(0.15261106695463353), 'classifier__estimator__max_depth': -1, 'classifier__estimator__n_estimators': 195, 'classifier__estimator__num_leaves': 23, 'classifier__estimator__reg_alpha': np.float64(0.907566473926093), 'classifier__estimator__reg_lambda': np.float64(0.24929222914887494)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1-Score Ponderado do Modelo Otimizado (na Validação): 0.4665\n",
            "\n",
            "Relatório de Classificação Detalhado (Validação - LGBM Otimizado):\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "fdf_falha_desgaste_ferramenta       0.09      0.14      0.11        14\n",
            "   fdc_falha_dissipacao_calor       0.57      0.90      0.70        39\n",
            "            fp_falha_potencia       0.71      0.56      0.62        27\n",
            "   fte_falha_tensao_excessiva       0.36      0.44      0.39        32\n",
            "           fa_falha_aleatoria       0.00      0.00      0.00        13\n",
            "\n",
            "                    micro avg       0.42      0.53      0.47       125\n",
            "                    macro avg       0.35      0.41      0.37       125\n",
            "                 weighted avg       0.43      0.53      0.47       125\n",
            "                  samples avg       0.01      0.01      0.01       125\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. OTIMIZAÇÃO DO XGBOOST\n",
        "# ==============================================================================\n",
        "print(\"\\n\\n--- Iniciando a Otimização para o XGBoost ---\")\n",
        "\n",
        "# --- 3.1. Criação do Pipeline Base ---\n",
        "pipeline_xgb = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')))\n",
        "])\n",
        "\n",
        "# --- 3.2. Definição do Espaço de Busca de Hiperparâmetros ---\n",
        "param_dist_xgb = {\n",
        "    'classifier__estimator__n_estimators': randint(100, 1000),\n",
        "    'classifier__estimator__learning_rate': uniform(0.01, 0.3),\n",
        "    'classifier__estimator__max_depth': randint(3, 10),\n",
        "    'classifier__estimator__subsample': uniform(0.7, 0.3), # Fração de amostras\n",
        "    'classifier__estimator__colsample_bytree': uniform(0.7, 0.3), # Fração de features\n",
        "    'classifier__estimator__gamma': uniform(0, 0.5) # Parâmetro de regularização\n",
        "}\n",
        "\n",
        "# --- 3.3. Configuração e Execução do RandomizedSearchCV ---\n",
        "random_search_xgb = RandomizedSearchCV(\n",
        "    pipeline_xgb,\n",
        "    param_distributions=param_dist_xgb,\n",
        "    n_iter=50,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=weighted_f1_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Executando a busca\n",
        "random_search_xgb.fit(X_train, y_train_limpo)\n",
        "\n",
        "# --- 3.4. Análise dos Resultados da Otimização (XGBoost) ---\n",
        "print(\"\\n--- Resultados da Otimização do XGBoost ---\")\n",
        "print(f\"Melhor F1-Score Ponderado (em CV): {random_search_xgb.best_score_:.4f}\")\n",
        "print(\"Melhores Hiperparâmetros Encontrados:\")\n",
        "print(random_search_xgb.best_params_)\n",
        "\n",
        "# Avaliando o melhor modelo encontrado no conjunto de VALIDAÇÃO\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "y_val_pred_xgb = best_xgb_model.predict(X_val)\n",
        "f1_val_xgb = f1_score(y_val_cleaned_for_eval, y_val_pred_xgb, average='weighted')\n",
        "print(f\"\\nF1-Score Ponderado do Modelo Otimizado (na Validação): {f1_val_xgb:.4f}\")\n",
        "print(\"\\nRelatório de Classificação Detalhado (Validação - XGBoost Otimizado):\")\n",
        "print(classification_report(y_val_cleaned_for_eval, y_val_pred_xgb, target_names=target_cols, zero_division=0))"
      ],
      "metadata": {
        "id": "W5Ysv7rO-NLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052bcf35-fbfb-4dcf-e275-d11dd98d0fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Iniciando a Otimização para o XGBoost ---\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. CONCLUSÃO DA SESSÃO DE OTIMIZAÇÃO\n",
        "# ==============================================================================\n",
        "print(\"\\n\\n--- Comparativo Final Após Otimização (no Conjunto de Validação) ---\")\n",
        "\n",
        "# Seus resultados da baseline (para comparação)\n",
        "baseline_lgbm_f1 = 0.460584\n",
        "baseline_xgb_f1 = 0.374331\n",
        "\n",
        "print(f\"LightGBM Baseline: {baseline_lgbm_f1:.4f}  |  LightGBM Otimizado: {f1_val_lgbm:.4f}\")\n",
        "print(f\"XGBoost Baseline:  {baseline_xgb_f1:.4f}  |  XGBoost Otimizado:  {f1_val_xgb:.4f}\")\n",
        "\n",
        "# Decisão do modelo campeão final\n",
        "if f1_val_lgbm > f1_val_xgb:\n",
        "    modelo_campeao = best_lgbm_model\n",
        "    nome_campeao = \"LightGBM Otimizado\"\n",
        "    f1_campeao = f1_val_lgbm\n",
        "else:\n",
        "    modelo_campeao = best_xgb_model\n",
        "    nome_campeao = \"XGBoost Otimizado\"\n",
        "    f1_campeao = f1_val_xgb\n",
        "\n",
        "print(f\"\\nO modelo campeão após a otimização é o '{nome_campeao}' com um F1-Score de {f1_campeao:.4f} no conjunto de validação.\")\n",
        "print(\"\\nPróximo passo: Avaliar este modelo final no conjunto de TESTE para obter a performance final do projeto.\")"
      ],
      "metadata": {
        "id": "QBkmO-iL-UqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJABWMuVC_6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SESSÃO 04: AVALIAÇÃO FINAL NO CONJUNTO DE TESTE\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 0. Importações Adicionais (se necessário) ---\n",
        "# Geralmente, as métricas e bibliotecas de visualização já foram importadas.\n",
        "# Apenas para garantir a autonomia do script:\n",
        "from sklearn.metrics import hamming_loss, jaccard_score, classification_report, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# modelo_campeao: O pipeline do melhor modelo otimizado (LGBM ou XGBoost).\n",
        "# nome_campeao: O nome do modelo campeão.\n",
        "# X_test, y_test: O conjunto de teste, guardado desde o início.\n",
        "# target_cols: A lista com os nomes das colunas de falha.\n",
        "\n",
        "print(f\"--- Iniciando a Avaliação Final do Modelo '{nome_campeao}' ---\")\n",
        "\n",
        "# --- 1. Realizando Previsões no Conjunto de Teste ---\n",
        "# Justificativa: Aplicamos o pipeline final e otimizado ao conjunto de teste.\n",
        "# Todas as etapas de pré-processamento (imputação, escalonamento, etc.)\n",
        "# são aplicadas de forma consistente, usando os parâmetros aprendidos nos\n",
        "# dados de treino.\n",
        "y_pred_test = modelo_campeao.predict(X_test)\n",
        "\n",
        "# --- 2. Cálculo e Apresentação das Métricas Finais ---\n",
        "# Justificativa: Calculamos as mesmas métricas usadas anteriormente para\n",
        "# ter uma avaliação consistente e imparcial do desempenho do modelo.\n",
        "\n",
        "print(\"\\n--- MÉTRICAS DE DESEMPENHO NO CONJUNTO DE TESTE ---\")\n",
        "final_h_loss = hamming_loss(y_test, y_pred_test)\n",
        "final_j_score = jaccard_score(y_test, y_pred_test, average='samples')\n",
        "final_f1_w = f1_score(y_test, y_pred_test, average='weighted')\n",
        "\n",
        "print(f\"  -> Hamming Loss: {final_h_loss:.4f}\")\n",
        "print(f\"  -> Jaccard Score (samples): {final_j_score:.4f}\")\n",
        "print(f\"  -> Weighted F1-Score: {final_f1_w:.4f}\")\n",
        "\n",
        "# --- 3. Relatório de Classificação Detalhado ---\n",
        "# Justificativa: Este relatório é vital para entender a performance do\n",
        "# modelo para cada tipo de falha individualmente. Ele nos mostra onde o\n",
        "# modelo é forte e onde ele pode ter dificuldades.\n",
        "\n",
        "print(\"\\n--- RELATÓRIO DE CLASSIFICAÇÃO FINAL (POR TIPO DE FALHA) ---\")\n",
        "final_report = classification_report(y_test, y_pred_test, target_names=target_cols, zero_division=0)\n",
        "print(final_report)\n",
        "\n",
        "# --- 4. Análise Visual com Matrizes de Confusão ---\n",
        "# Justificativa: A matriz de confusão nos dá uma visão clara dos acertos e\n",
        "# erros para cada classe. Para problemas multi-label, geramos uma matriz\n",
        "# para cada tipo de falha.\n",
        "\n",
        "print(\"\\n--- GERANDO MATRIZES DE CONFUSÃO PARA CADA TIPO DE FALHA ---\")\n",
        "fig, axes = plt.subplots(1, len(target_cols), figsize=(20, 4))\n",
        "fig.suptitle(f'Matrizes de Confusão por Tipo de Falha - Modelo {nome_campeao}', fontsize=16)\n",
        "\n",
        "for i, col in enumerate(target_cols):\n",
        "    # Extrai os valores verdadeiros e previstos para a falha atual\n",
        "    true_labels = y_test[col]\n",
        "    pred_labels = y_pred_test[:, i]\n",
        "\n",
        "    # Gera a matriz de confusão\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
        "                xticklabels=['Sem Falha', 'Com Falha'],\n",
        "                yticklabels=['Sem Falha', 'Com Falha'])\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "    axes[i].set_ylabel('Verdadeiro')\n",
        "    axes[i].set_xlabel('Previsto')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Uq2jxJ1mGYhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 5. Análise de Features Importantes (do modelo final) ---\n",
        "# Justificativa: Revisitamos a importância das features para gerar insights\n",
        "# de negócio a partir do nosso modelo mais performático.\n",
        "try:\n",
        "    classifier_step = modelo_campeao.named_steps['classifier']\n",
        "    feature_importances = [estimator.feature_importances_ for estimator in classifier_step.estimators_]\n",
        "    avg_importances = np.mean(feature_importances, axis=0)\n",
        "    feature_names_raw = modelo_campeao.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names_raw,\n",
        "        'Importance': avg_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(\"\\n\\n--- TOP 10 FEATURES MAIS IMPORTANTES (MODELO FINAL) ---\")\n",
        "    print(importance_df.head(10))\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(10), palette='viridis')\n",
        "    plt.title(f'Top 10 Features Mais Importantes - Modelo {nome_campeao}')\n",
        "    plt.xlabel('Importância Média')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except AttributeError:\n",
        "    print(f\"\\nO modelo {nome_campeao} não suporta a análise de 'feature_importances_'.\")"
      ],
      "metadata": {
        "id": "WWcYZXzYATlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}